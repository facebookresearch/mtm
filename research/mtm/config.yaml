defaults:
    - datasets: d4rl
    - override hydra/launcher: slurm
    - override hydra/output: local
    - _self_

model_config:
    _target_: research.mtm.models.mtm_model.MTMConfig
    norm: "none"
    n_embd: 512
    n_enc_layer: 2
    n_dec_layer: 1
    n_head: 4
    dropout: 0.0
    loss_keys: null
    latent_dim: 32

state_only_dataset: null

args:
    _target_: research.mtm.train.RunConfig
    seed: 0
    batch_size: 1024
    n_workers: 10
    traj_length: 4

    ### Debug
    # log_every: 1
    # print_every: 1
    # eval_every: 1
    # save_every: 1
    log_every: 100
    print_every: 1000
    eval_every: 20000
    # eval_every: 5000
    save_every: 10000

    device: cuda
    # mask_ratios: [0.4, 0.5, 0.6, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]
    mask_ratios: [0.7, 0.8, 0.85, 0.9, 0.95, 1.0]
    mask_patterns: ["AUTO_MASK"]
    warmup_steps: 40000
    # num_train_steps: 1000000
    # num_train_steps: 1000001
    num_train_steps: 500001
    # num_train_steps: 100000
    learning_rate: 0.0001
    weight_decay:  0.01
    mode_weights: [0.2,0.0,0.8]
    tsp_ratio: 1


wandb:
  project: reacher_experiments
  entity: mtm_team
  resume: null
  # resume: allow
  # mode: disabled

# general outputs
job_name: job

hydra:
    job:
        name: mtm_mae
        chdir: True
