# @package _global_
defaults:
    - override /datasets: d4rl

tokenizers:
    states:
      _target_: research.mtm.tokenizers.continuous.ContinuousTokenizer.create
    actions:
      _target_: research.mtm.tokenizers.continuous.ContinuousTokenizer.create
    rewards:
      _target_: research.mtm.tokenizers.continuous.ContinuousTokenizer.create
    returns:
      _target_: research.mtm.tokenizers.continuous.ContinuousTokenizer.create


dataset:
    use_reward: True

args:
    _target_: research.mtm.train.RunConfig
    batch_size: 512
    n_workers: 0
    model_config:
      traj_length: 4
      norm: "l2"
      n_enc_layer: 1
      n_dec_layer: 1
      n_head: 2
      n_embd: 64
    log_every: 100
    print_every: 1000
    eval_every: 10000
    save_every: 10000
    mask_patterns: ["RANDOM", "ID", "FD", "GOAL"]

wandb:
    project: "p_d4rl_cont_12_20_l2"
    resume: allow
