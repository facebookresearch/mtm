defaults:
    - datasets: d4rl
    - override hydra/launcher: slurm
    - override hydra/output: local
    - _self_

model_config:
    _target_: research.mtm.models.mtm_model.MTMConfig
    norm: "none"
    n_embd: 512
    n_enc_layer: 2
    n_dec_layer: 1
    n_head: 4
    dropout: 0.1
    loss_keys: null
    latent_dim: null

state_only_dataset: null

args:
    _target_: research.mtm.train.RunConfig
    seed: 0
    batch_size: 2048
    n_workers: 10
    traj_length: 4

    ### Debug
    # log_every: 1
    # print_every: 1
    # eval_every: 1
    # save_every: 1

    log_every: 100
    print_every: 1000
    eval_every: 20000
    save_every: 10000

    device: cuda
    mask_ratios: [0.5, 0.6, 0.7, 0.8, 0.85, 0.9, 0.95, 1.0]
    mask_patterns: ["AUTO_MASK"]
    warmup_steps: 40000
    num_train_steps: 140010
    learning_rate: 0.0001
    weight_decay:  0.005
    mode_weights: [0.2, 0.1, 0.7]
    tsp_ratio: 1


wandb:
  project: experiments
  entity: ""
  resume: null
  # resume: allow

job_name: job

hydra:
    job:
        name: mtm_mae
        chdir: True
