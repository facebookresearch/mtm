{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1ba950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MUJOCO_GL\"] = \"egl\"\n",
    "    \n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Callable, Dict, Tuple\n",
    "from pprint import pprint\n",
    "\n",
    "import dcargs\n",
    "import glob\n",
    "import hydra\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from research.logger import WandBLogger, WandBLoggerConfig\n",
    "from research.mtm.models.mtm_model import MaskedDP, MTMConfig, make_plots_with_masks\n",
    "from research.mtm.tokenizers.base import Tokenizer, TokenizerManager\n",
    "import mediapy as media\n",
    "from research.mtm.train import RunConfig\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from research.utils.plot_utils import PlotHandler as ph\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b8621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cheetah\n",
    "path = \"/private/home/philippwu/mtm/outputs/mtm_mae/2022-12-05_22-24-33/98_+experiments=d4rl_discrete,args.mask_patterns=[FULL_RANDOM,RANDOM,GOAL,GOAL_N,ID,FD],dataset.env_name=halfcheetah-expert-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facb590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hopper\n",
    "path = \"/private/home/philippwu/mtm/outputs/mtm_mae/2022-12-05_18-37-25/56_+experiments=d4rl_mixed,args.mask_patterns=[FULL_RANDOM,RANDOM,FD],dataset.env_name=hopper-expert-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828000a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/private/home/philippwu/mtm/outputs/mtm_mae/2023-01-04_09-08-01/0_args.traj_length=2,dataset.env_name=walker2d-medium-expert-v2,model_config.task=rcbc,wandb.project=rcbc_med_exp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad27bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find checkpoints in the directory\n",
    "steps = []\n",
    "names = []\n",
    "paths_ = os.listdir(path)\n",
    "for name in [os.path.join(path, n) for n in paths_ if \"pt\" in n]:\n",
    "    step = os.path.basename(name).split(\"_\")[-1].split(\".\")[0]\n",
    "    steps.append(int(step))\n",
    "    names.append(name)\n",
    "    print(name)\n",
    "\n",
    "ckpt_path = names[np.argmax(steps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8556f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd54da7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt_path = '/private/home/philippwu/mtm/outputs/mtm_mae/2022-11-17_18-22-57/1_+experiments=exorl_continuous_rew_qpos,args.mask_patterns=[RANDOM,GOAL,ID,FD],args.model_config.n_dec_layer=1,args.model_config.n_enc_layer=1,args.model_config.n_head=4/model_640000.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44562698",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = Path(\"files/d4rl\")\n",
    "folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c41418b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2a185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.load(ckpt_path)[\"step\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1296438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hydra_cfg = OmegaConf.load(os.path.join(path, \".hydra/config.yaml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41892c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hydra_cfg.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7da979",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = hydra.utils.instantiate(hydra_cfg.args)\n",
    "pprint(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b5b55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hydra_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e6d55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = hydra.utils.call(\n",
    "    hydra_cfg.dataset, seq_steps=cfg.traj_length\n",
    ")\n",
    "print(\"Train set size =\", len(train_dataset))\n",
    "print(\"Validation set size =\", len(val_dataset))\n",
    "\n",
    "tokenizers: Dict[str, Tokenizer] = {\n",
    "    k: hydra.utils.call(v, key=k, train_dataset=train_dataset)\n",
    "    for k, v in hydra_cfg.tokenizers.items()\n",
    "}\n",
    "tokenizer_manager = TokenizerManager(tokenizers)\n",
    "discrete_map: Dict[str, bool] = {}\n",
    "for k, v in tokenizers.items():\n",
    "    discrete_map[k] = v.discrete\n",
    "print(tokenizers)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    # shuffle=True,\n",
    "    pin_memory=True,\n",
    "    batch_size=cfg.batch_size,\n",
    "    num_workers=cfg.n_workers,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    # shuffle=False,\n",
    "    batch_size=cfg.batch_size,\n",
    "    num_workers=cfg.n_workers,\n",
    ")\n",
    "train_batch = next(iter(train_loader))\n",
    "tokenized = tokenizer_manager.encode(train_batch)\n",
    "data_shapes = {}\n",
    "for k, v in tokenized.items():\n",
    "    data_shapes[k] = v.shape[-2:]\n",
    "print(data_shapes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16073d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = val_dataset.dataset.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fddc4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "image = env.sim.render(640, 480, camera_name=\"track\")[::-1]\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeb414b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_trajectory_with_metadata = val_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e45539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_trajectory_with_metadata[\"states\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b79999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(env.sim.set_state_from_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d63f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "phys_state = np.zeros(len(sample_trajectory_with_metadata[\"states\"][0]) + 2)\n",
    "phys_state[2:] = sample_trajectory_with_metadata[\"states\"][0]\n",
    "env.sim.set_state_from_flattened(phys_state)\n",
    "env.sim.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d749468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = env.sim.render(640, 480, camera_name=\"track\")[::-1]\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5603f458",
   "metadata": {},
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f00bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MaskedDP(data_shapes, cfg.model_config)\n",
    "model.to(cfg.device)\n",
    "model.train()\n",
    "\n",
    "# load weights\n",
    "model.load_state_dict(torch.load(ckpt_path)[\"model\"])\n",
    "model.eval()\n",
    "\n",
    "t_len = cfg.model_config.traj_length\n",
    "prediction_steps = t_len - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba55caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "env.sim.set_state_from_flattened(phys_state)\n",
    "env.sim.forward()\n",
    "    \n",
    "images_open_loop = [env.sim.render(640, 480, camera_name=\"track\")[::-1]]\n",
    "execute_actions = sample_trajectory_with_metadata[\"actions\"]\n",
    "\n",
    "for idx, action in enumerate(execute_actions):\n",
    "    obs = env.step(action)[0]\n",
    "    image = env.sim.render(640, 480, camera_name=\"track\")[::-1]\n",
    "    images_open_loop.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40da4c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "media.show_video(images_open_loop, fps=30)\n",
    "media.write_video(folder / \"gt.gif\", np.array(images_open_loop), codec='gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2321cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run closed loop\n",
    "batch_torch = {\n",
    "    \"states\": torch.from_numpy(sample_trajectory_with_metadata[\"states\"])\n",
    "    .to(cfg.device, torch.float32)\n",
    "    .unsqueeze(0),\n",
    "    \"actions\": torch.from_numpy(sample_trajectory_with_metadata[\"actions\"])\n",
    "    .to(cfg.device)\n",
    "    .unsqueeze(0),\n",
    "    \"rewards\": torch.from_numpy(sample_trajectory_with_metadata[\"rewards\"])\n",
    "    .to(cfg.device)\n",
    "    .unsqueeze(0),\n",
    "}\n",
    "\n",
    "\n",
    "# goalreaching mask\n",
    "state_mask = torch.ones(batch_torch[\"states\"].shape[1])\n",
    "# state_mask[1:-1] = 0\n",
    "action_mask = torch.zeros(batch_torch[\"actions\"].shape[1])\n",
    "reward_mask = torch.zeros(batch_torch[\"rewards\"].shape[1])\n",
    "masks = {\"states\": state_mask, \"actions\": action_mask, \"rewards\": reward_mask}\n",
    "masks_torch = {k: v.to(cfg.device) for k, v in masks.items()}\n",
    "\n",
    "env.sim.set_state_from_flattened(phys_state)\n",
    "env.sim.forward()\n",
    "\n",
    "images_close_loop = [env.sim.render(640, 480)[::-1]]\n",
    "traj_real_cl = defaultdict(list)\n",
    "traj_real_cl[\"states\"].append(sample_trajectory_with_metadata[\"states\"][0])\n",
    "\n",
    "\n",
    "for i in range(prediction_steps):\n",
    "    encoded_batch = tokenizer_manager.encode(batch_torch)\n",
    "    predicted_trajectories = model(encoded_batch, masks_torch)\n",
    "    decoded_trajectories = tokenizer_manager.decode(predicted_trajectories)\n",
    "    \n",
    "    a = decoded_trajectories[\"actions\"][0][i].detach().cpu().numpy()\n",
    "    batch_torch[\"actions\"][0][i] = torch.tensor(a, device=\"cuda\")\n",
    "    traj_real_cl[\"actions\"].append(a)\n",
    "    ret = env.step(np.clip(a, -1, 1))\n",
    "    obs = ret[0]\n",
    "    rew = ret[1]\n",
    "    traj_real_cl[\"rewards\"].append([rew])\n",
    "    traj_real_cl[\"states\"].append(obs)\n",
    "    image = env.sim.render(640, 480)[::-1]\n",
    "    images_close_loop.append(image)\n",
    "    masks[\"states\"][i] = 1\n",
    "    masks[\"actions\"][i] = 1\n",
    "    masks_torch = {k: v.to(cfg.device) for k, v in masks.items()}\n",
    "    batch_torch[\"states\"][0][i+1] = torch.tensor(obs, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d44e3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "media.show_video(images_close_loop, fps=30)\n",
    "media.write_video(folder / \"close_loop.gif\", images_close_loop, fps=30, codec='gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2ca7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_trajectories.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c7680a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_n_plots = 3\n",
    "for k, _ in decoded_trajectories.items():\n",
    "    traj = batch_torch[k].cpu().numpy()[0]\n",
    "    pred_traj = decoded_trajectories[k][0].detach().cpu().numpy()\n",
    "    mask = masks[k]\n",
    "    for i in range(min(max_n_plots, traj.shape[-1])):\n",
    "        gt_i = traj[:, i]\n",
    "        re_i = pred_traj[:, i]\n",
    "        real_i = np.array(traj_real_cl[k])[:, i]\n",
    "        if len(mask.shape) == 1:\n",
    "            # only along time dimension: repeat across the given dimension\n",
    "            mask = mask[:, None].repeat(1, traj.shape[1])\n",
    "        select_mask = mask[:, i].cpu().numpy()\n",
    "        unmasked_gt_i = gt_i[select_mask == 1]\n",
    "        unmasked_gt_i_index = np.arange(len(gt_i))[select_mask == 1]\n",
    "        vmax = max(np.max(gt_i), np.max(re_i))\n",
    "        vmin = min(np.min(gt_i), np.min(re_i))\n",
    "        y_range = vmax - vmin\n",
    "        with ph.plot_context() as (fig, ax):\n",
    "\n",
    "            ax.plot(gt_i, \"-o\", label=\"ground truth\")\n",
    "            ax.plot(\n",
    "                re_i, \"-o\", label=\"reconstructed\", markerfacecolor=\"none\"\n",
    "            )\n",
    "            ax.plot(\n",
    "                unmasked_gt_i_index,\n",
    "                unmasked_gt_i,\n",
    "                \"o\",\n",
    "                label=\"unmasked ground truth\",\n",
    "            )\n",
    "            ax.plot(\n",
    "                real_i, \".\", label=\"real\"\n",
    "            )\n",
    "            ax.set_ylim(\n",
    "                vmin - y_range / 5,\n",
    "                vmax + y_range / 5,\n",
    "            )\n",
    "            ax.legend()\n",
    "            ax.set_title(f\"{k}_{i}\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a24cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run closed loop\n",
    "batch_torch = {\n",
    "    \"states\": torch.from_numpy(sample_trajectory_with_metadata[\"states\"])\n",
    "    .to(cfg.device, torch.float32)\n",
    "    .unsqueeze(0),\n",
    "    \"actions\": torch.from_numpy(sample_trajectory_with_metadata[\"actions\"])\n",
    "    .to(cfg.device)\n",
    "    .unsqueeze(0),\n",
    "    \"rewards\": torch.from_numpy(sample_trajectory_with_metadata[\"rewards\"])\n",
    "    .to(cfg.device)\n",
    "    .unsqueeze(0),\n",
    "}\n",
    "\n",
    "\n",
    "# goalreaching mask\n",
    "state_mask = torch.ones(batch_torch[\"states\"].shape[1])\n",
    "# state_mask[1:-1] = 0\n",
    "action_mask = torch.zeros(batch_torch[\"actions\"].shape[1])\n",
    "reward_mask = torch.zeros(batch_torch[\"rewards\"].shape[1])\n",
    "masks = {\"states\": state_mask, \"actions\": action_mask, \"rewards\": reward_mask}\n",
    "masks_torch = {k: v.to(cfg.device) for k, v in masks.items()}\n",
    "\n",
    "encoded_batch = tokenizer_manager.encode(batch_torch)\n",
    "predicted_trajectories = model(encoded_batch, masks_torch)\n",
    "decoded_trajectories = tokenizer_manager.decode(predicted_trajectories)\n",
    "\n",
    "env.sim.set_state_from_flattened(phys_state)\n",
    "env.sim.forward()\n",
    "\n",
    "images_close_loop = [env.sim.render(640, 480)[::-1]]\n",
    "traj_real_cl = defaultdict(list)\n",
    "traj_real_cl[\"states\"].append(sample_trajectory_with_metadata[\"states\"][0])\n",
    "for act in decoded_trajectories[\"actions\"][0].detach().cpu().numpy():\n",
    "    traj_real_cl[\"actions\"].append(act)\n",
    "    ret = env.step(np.clip(act, -1, 1))\n",
    "    obs = ret[0]\n",
    "    rew = ret[1]\n",
    "    traj_real_cl[\"rewards\"].append([rew])\n",
    "    traj_real_cl[\"states\"].append(obs)\n",
    "    image = env.sim.render(640, 480)[::-1]\n",
    "    images_close_loop.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02232f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "media.show_video(images_open_loop, fps=30)\n",
    "media.write_video(folder / \"open_loop.gif\", np.array(images_open_loop), codec='gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdec6e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_n_plots = 3\n",
    "for k, _ in decoded_trajectories.items():\n",
    "    traj = batch_torch[k].cpu().numpy()[0]\n",
    "    pred_traj = decoded_trajectories[k][0].detach().cpu().numpy()\n",
    "    mask = masks[k]\n",
    "    for i in range(min(max_n_plots, traj.shape[-1])):\n",
    "        gt_i = traj[:, i]\n",
    "        re_i = pred_traj[:, i]\n",
    "        real_i = np.array(traj_real_cl[k])[:, i]\n",
    "        if len(mask.shape) == 1:\n",
    "            # only along time dimension: repeat across the given dimension\n",
    "            mask = mask[:, None].repeat(1, traj.shape[1])\n",
    "        select_mask = mask[:, i].cpu().numpy()\n",
    "        unmasked_gt_i = gt_i[select_mask == 1]\n",
    "        unmasked_gt_i_index = np.arange(len(gt_i))[select_mask == 1]\n",
    "        vmax = max(np.max(gt_i), np.max(re_i))\n",
    "        vmin = min(np.min(gt_i), np.min(re_i))\n",
    "        y_range = vmax - vmin\n",
    "        with ph.plot_context() as (fig, ax):\n",
    "\n",
    "            ax.plot(gt_i, \"-o\", label=\"ground truth\")\n",
    "            ax.plot(\n",
    "                re_i, \"-o\", label=\"reconstructed\", markerfacecolor=\"none\"\n",
    "            )\n",
    "            ax.plot(\n",
    "                unmasked_gt_i_index,\n",
    "                unmasked_gt_i,\n",
    "                \"o\",\n",
    "                label=\"unmasked ground truth\",\n",
    "            )\n",
    "            ax.plot(\n",
    "                real_i, \".\", label=\"real\"\n",
    "            )\n",
    "            ax.set_ylim(\n",
    "                vmin - y_range / 5,\n",
    "                vmax + y_range / 5,\n",
    "            )\n",
    "            ax.legend()\n",
    "            ax.set_title(f\"{k}_{i}\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f07413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c610c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e686e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb14f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49a8539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run closed loop\n",
    "batch_torch = {\n",
    "    \"states\": torch.from_numpy(sample_trajectory_with_metadata[\"states\"])\n",
    "    .to(cfg.device, torch.float32)\n",
    "    .unsqueeze(0),\n",
    "    \"actions\": torch.from_numpy(sample_trajectory_with_metadata[\"actions\"])\n",
    "    .to(cfg.device)\n",
    "    .unsqueeze(0),\n",
    "    \"rewards\": torch.from_numpy(sample_trajectory_with_metadata[\"rewards\"])\n",
    "    .to(cfg.device)\n",
    "    .unsqueeze(0),\n",
    "}\n",
    "\n",
    "\n",
    "# goalreaching mask\n",
    "state_mask = torch.ones(batch_torch[\"states\"].shape[1])\n",
    "state_mask[1:] = 0\n",
    "action_mask = torch.zeros(batch_torch[\"actions\"].shape[1])\n",
    "reward_mask = torch.zeros(batch_torch[\"rewards\"].shape[1])\n",
    "masks = {\"states\": state_mask, \"actions\": action_mask, \"rewards\": reward_mask}\n",
    "masks_torch = {k: v.to(cfg.device) for k, v in masks.items()}\n",
    "\n",
    "encoded_batch = tokenizer_manager.encode(batch_torch)\n",
    "predicted_trajectories = model(encoded_batch, masks_torch)\n",
    "decoded_trajectories = tokenizer_manager.decode(predicted_trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafb9b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n_plots = 3\n",
    "\n",
    "for k, _ in decoded_trajectories.items():\n",
    "    traj = batch_torch[k].cpu().numpy()[0]\n",
    "    pred_traj = decoded_trajectories[k][0].detach().cpu().numpy()\n",
    "    mask = masks[k]\n",
    "    for i in range(min(max_n_plots, traj.shape[-1])):\n",
    "        gt_i = traj[:, i]\n",
    "        re_i = pred_traj[:, i]\n",
    "        if len(mask.shape) == 1:\n",
    "            # only along time dimension: repeat across the given dimension\n",
    "            mask = mask[:, None].repeat(1, traj.shape[1])\n",
    "        select_mask = mask[:, i].cpu().numpy()\n",
    "        unmasked_gt_i = gt_i[select_mask == 1]\n",
    "        unmasked_gt_i_index = np.arange(len(gt_i))[select_mask == 1]\n",
    "        vmax = max(np.max(gt_i), np.max(re_i))\n",
    "        vmin = min(np.min(gt_i), np.min(re_i))\n",
    "        y_range = vmax - vmin\n",
    "        with ph.plot_context() as (fig, ax):\n",
    "\n",
    "            ax.plot(gt_i, \"-o\", label=\"ground truth\")\n",
    "            ax.plot(\n",
    "                re_i, \"-o\", label=\"reconstructed\", markerfacecolor=\"none\"\n",
    "            )\n",
    "            ax.plot(\n",
    "                unmasked_gt_i_index,\n",
    "                unmasked_gt_i,\n",
    "                \"o\",\n",
    "                label=\"unmasked ground truth\",\n",
    "            )\n",
    "            ax.set_ylim(\n",
    "                vmin - y_range / 5,\n",
    "                vmax + y_range / 5,\n",
    "            )\n",
    "            ax.legend()\n",
    "            ax.set_title(f\"{k}_{i}\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584975eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34abac73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load 5 models\n",
    "# do take same history and pass into all models\n",
    "# pick top k based on rewards\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb2558b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
