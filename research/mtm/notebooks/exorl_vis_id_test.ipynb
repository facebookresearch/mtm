{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1ba950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MUJOCO_GL\"] = \"egl\"\n",
    "    \n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Callable, Dict, Tuple\n",
    "from pprint import pprint\n",
    "\n",
    "import dcargs\n",
    "import glob\n",
    "import hydra\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from research.logger import WandBLogger, WandBLoggerConfig\n",
    "from research.mtm.models.mtm_model import MaskedDP, MTMConfig, make_plots_with_masks\n",
    "from research.mtm.tokenizers.base import Tokenizer, TokenizerManager\n",
    "import mediapy as media\n",
    "from research.mtm.train import RunConfig\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from research.utils.plot_utils import PlotHandler as ph\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157cc2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [RANDOM,GOAL,ID,FD],args.model_config.n_dec_layer=2\n",
    "path = \"/private/home/philippwu/mtm/outputs/mtm_mae/2022-11-17_18-23-27/1_+experiments=exorl_continuous_rew_qpos,args.mask_patterns=[RANDOM,GOAL,ID,FD],args.model_config.n_dec_layer=2,args.model_config.n_enc_layer=2,args.model_config.n_head=4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c2d5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discrete\n",
    "# [RANDOM,GOAL,ID,FD],args.model_config.n_dec_layer=1\n",
    "path = \"/private/home/philippwu/mtm/outputs/mtm_mae/2022-11-18_22-20-17/1_+experiments=exorl_discrete_rew_qpos,args.mask_patterns=[RANDOM,GOAL,ID,FD],args.model_config.n_dec_layer=1,args.model_config.n_enc_layer=2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad27bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find checkpoints in the directory\n",
    "steps = []\n",
    "names = []\n",
    "paths_ = os.listdir(path)\n",
    "for name in [os.path.join(path, n) for n in paths_ if \"pt\" in n]:\n",
    "    step = os.path.basename(name).split(\"_\")[-1].split(\".\")[0]\n",
    "    steps.append(int(step))\n",
    "    names.append(name)\n",
    "    # print(name)\n",
    "\n",
    "ckpt_path = names[np.argmax(steps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2a185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242c2692",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7da979",
   "metadata": {},
   "outputs": [],
   "source": [
    "hydra_cfg = OmegaConf.load(os.path.join(path, \".hydra/config.yaml\"))\n",
    "hydra_cfg.dataset.train_max_size = 10000\n",
    "hydra_cfg.dataset.val_max_size = 10000\n",
    "del hydra_cfg.args.wandb_config\n",
    "cfg = hydra.utils.instantiate(hydra_cfg.args)\n",
    "pprint(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e6d55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = hydra.utils.call(\n",
    "    hydra_cfg.dataset, seq_steps=cfg.model_config.traj_length\n",
    ")\n",
    "print(\"Train set size =\", len(train_dataset))\n",
    "print(\"Validation set size =\", len(val_dataset))\n",
    "\n",
    "tokenizers: Dict[str, Tokenizer] = {\n",
    "    k: hydra.utils.call(v, key=k, train_dataset=train_dataset)\n",
    "    for k, v in hydra_cfg.tokenizers.items()\n",
    "}\n",
    "tokenizer_manager = TokenizerManager(tokenizers)\n",
    "discrete_map: Dict[str, bool] = {}\n",
    "for k, v in tokenizers.items():\n",
    "    discrete_map[k] = v.discrete\n",
    "print(tokenizers)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    # shuffle=True,\n",
    "    pin_memory=True,\n",
    "    batch_size=cfg.batch_size,\n",
    "    num_workers=cfg.n_workers,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    # shuffle=False,\n",
    "    batch_size=cfg.batch_size,\n",
    "    num_workers=cfg.n_workers,\n",
    ")\n",
    "train_batch = next(iter(train_loader))\n",
    "tokenized = tokenizer_manager.encode(train_batch)\n",
    "data_shapes = {}\n",
    "for k, v in tokenized.items():\n",
    "    data_shapes[k] = v.shape[-2:]\n",
    "print(data_shapes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16073d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = val_dataset._env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fddc4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "image = env.physics.render(480, 640)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f0807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_trajectory_with_metadata = val_dataset.sample(22, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bdcc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_trajectory_with_metadata.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5603f458",
   "metadata": {},
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f488be",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.load(ckpt_path)[\"step\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f00bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MaskedDP(data_shapes, cfg.model_config)\n",
    "model.to(cfg.device)\n",
    "model.train()\n",
    "\n",
    "# load weights\n",
    "model.load_state_dict(torch.load(ckpt_path)[\"model\"])\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1082725",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_trajectory_with_metadata[\"observations\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230568bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_torch = {\n",
    "    \"states\": torch.from_numpy(sample_trajectory_with_metadata[\"observations\"][:,:15])\n",
    "    .to(cfg.device)\n",
    "    .unsqueeze(0),\n",
    "    \"rewards\": torch.from_numpy(sample_trajectory_with_metadata[\"rewards\"])\n",
    "    .to(cfg.device)\n",
    "    .unsqueeze(0),\n",
    "    \"actions\": torch.from_numpy(sample_trajectory_with_metadata[\"actions\"])\n",
    "    .to(cfg.device)\n",
    "    .unsqueeze(0),\n",
    "}\n",
    "\n",
    "\n",
    "# goalreaching mask\n",
    "state_mask = torch.ones(batch_torch[\"states\"].shape[1])\n",
    "action_mask = torch.zeros(batch_torch[\"actions\"].shape[1])\n",
    "masks = {\"states\": state_mask, \"rewards\": state_mask, \"actions\": action_mask}\n",
    "masks_torch = {k: v.to(cfg.device) for k, v in masks.items()}\n",
    "\n",
    "\n",
    "# #shorten everything to the prediction_steps\n",
    "# for k in masks.keys():\n",
    "#     masks_torch[k] = masks_torch[k][:prediction_steps+1]\n",
    "#     batch_torch[k] = batch_torch[k][:prediction_steps+1]\n",
    "\n",
    "encoded_batch = tokenizer_manager.encode(batch_torch)\n",
    "predicted_trajectories = model(encoded_batch, masks_torch)\n",
    "decoded_trajectories = tokenizer_manager.decode(predicted_trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c9df3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_actions():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba55caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.physics.reset()\n",
    "with env.physics.reset_context():\n",
    "    env.physics.set_state(sample_trajectory_with_metadata[\"physics\"][0])\n",
    "    \n",
    "images_open_loop = [env.physics.render(480, 640, 0)]\n",
    "execute_actions = decoded_trajectories[\"actions\"].squeeze(0).detach().cpu().numpy()\n",
    "traj_real_ol = defaultdict(list)\n",
    "traj_real_ol[\"states\"].append(sample_trajectory_with_metadata[\"observations\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1611fecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, action in enumerate(execute_actions):\n",
    "    traj_real_ol[\"actions\"].append(action)\n",
    "    obs = env.step(action)\n",
    "    traj_real_ol[\"states\"].append(obs[\"observation\"])\n",
    "    image = env.physics.render(480, 640, 0)\n",
    "    images_open_loop.append(image)\n",
    "    \n",
    "traj_real_ol[\"states\"] = traj_real_ol[\"states\"][:-1]\n",
    "    # compare obs against data\n",
    "#     _obs = sample_trajectory_with_metadata[\"observations\"]\n",
    "#     np.testing.assert_allclose(obs, _obs[idx], atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40da4c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "media.show_video(images_open_loop, fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c7680a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n_plots = 15\n",
    "for k, _ in decoded_trajectories.items():\n",
    "    if k == \"rewards\":\n",
    "        continue\n",
    "    traj = batch_torch[k][0].detach().cpu().numpy()\n",
    "    pred_traj = decoded_trajectories[k][0].detach().cpu().numpy()\n",
    "    mask = masks[k]\n",
    "    for i in range(min(max_n_plots, traj.shape[-1])):\n",
    "        gt_i = traj[:, i]\n",
    "        re_i = pred_traj[:, i]\n",
    "        real_i = np.array(traj_real_ol[k])[:, i]\n",
    "        if len(mask.shape) == 1:\n",
    "            # only along time dimension: repeat across the given dimension\n",
    "            mask = mask[:, None].repeat(1, traj.shape[1])\n",
    "        select_mask = mask[:, i].cpu().numpy()\n",
    "        unmasked_gt_i = gt_i[select_mask == 1]\n",
    "        unmasked_gt_i_index = np.arange(len(gt_i))[select_mask == 1]\n",
    "        vmax = max(np.max(gt_i), np.max(re_i))\n",
    "        vmin = min(np.min(gt_i), np.min(re_i))\n",
    "        y_range = vmax - vmin\n",
    "        with ph.plot_context() as (fig, ax):\n",
    "\n",
    "            ax.plot(gt_i, \"-o\", label=\"ground truth\")\n",
    "            ax.plot(\n",
    "                re_i, \"-o\", label=\"reconstructed\", markerfacecolor=\"none\"\n",
    "            )\n",
    "            ax.plot(\n",
    "                unmasked_gt_i_index,\n",
    "                unmasked_gt_i,\n",
    "                \"o\",\n",
    "                label=\"unmasked ground truth\",\n",
    "            )\n",
    "            ax.plot(\n",
    "                real_i, \".\", label=\"real\"\n",
    "            )\n",
    "            ax.set_ylim(\n",
    "                vmin - y_range / 5,\n",
    "                vmax + y_range / 5,\n",
    "            )\n",
    "            ax.legend()\n",
    "            ax.set_title(f\"{k}_{i}\")\n",
    "            plt.show()\n",
    "#             eval_logs[\n",
    "#                 f\"{eval_name}/batch={batch_idx}|{i}_{k}\"\n",
    "#             ] = wandb.Image(ph.plot_as_image(fig))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f36905",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images_open_loop[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f6391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(images_open_loop[prediction_steps])\n",
    "# plt.show()\n",
    "# plt.imshow(images_open_loop[prediction_steps])\n",
    "# plt.show()\n",
    "# plt.imshow(images_close_loop[prediction_steps])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7f9395",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = images_gt[prediction_steps] - images_open_loop[prediction_steps]\n",
    "diff = (diff - np.min(diff)) / (np.max(diff) - np.min(diff))\n",
    "plt.imshow(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c89aa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = images_gt[prediction_steps] - images_close_loop[prediction_steps]\n",
    "diff = (diff - np.min(diff)) / (np.max(diff) - np.min(diff))\n",
    "plt.imshow(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e01117",
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_state = sample_trajectory_with_metadata[\"observations\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02232f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_cl = goal_state - traj_real_cl[\"states\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2049c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(diff_cl**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218fbaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_ol = goal_state - traj_real_ol[\"states\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff5b18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(diff_ol**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ffaa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.task.get_observation(env.physics)\n",
    "print(obs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f48ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "[o.shape for k, o in obs.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0030636",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
