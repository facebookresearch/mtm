{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1ba950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MUJOCO_GL\"] = \"egl\"\n",
    "    \n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Callable, Dict, Tuple\n",
    "from pprint import pprint\n",
    "\n",
    "import dcargs\n",
    "import glob\n",
    "import hydra\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from research.logger import WandBLogger, WandBLoggerConfig\n",
    "from research.mtm.models.mtm_model import MaskedDP, MTMConfig, make_plots_with_masks\n",
    "from research.mtm.tokenizers.base import Tokenizer, TokenizerManager\n",
    "import mediapy as media\n",
    "from research.mtm.train import RunConfig\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from research.utils.plot_utils import PlotHandler as ph\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74969f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/private/home/philippwu/mtm/outputs/mtm_mae/\"\n",
    "\n",
    "date = \"2022-11-07_15-08-22\" # continous\n",
    "extra = \"1_+experiments=exorl_continuous_rew,args.mask_patterns=[RANDOM,GOAL,ID,FD],args.model_config.n_dec_layer=6,args.model_config.n_enc_layer=6,args.model_config.n_head=4\" # random masks \n",
    "\n",
    "\n",
    "path = os.path.join(root, date, extra)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e34eb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [RANDOM,GOAL,ID,FD],args.model_config.n_dec_layer=1 \n",
    "path = \"/private/home/philippwu/mtm/outputs/mtm_mae/2022-11-17_18-22-57/1_+experiments=exorl_continuous_rew_qpos,args.mask_patterns=[RANDOM,GOAL,ID,FD],args.model_config.n_dec_layer=1,args.model_config.n_enc_layer=1,args.model_config.n_head=4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88422a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [RANDOM,GOAL,ID,FD],args.model_config.n_dec_layer=2\n",
    "# path = \"/private/home/philippwu/mtm/outputs/mtm_mae/2022-11-17_18-23-27/1_+experiments=exorl_continuous_rew_qpos,args.mask_patterns=[RANDOM,GOAL,ID,FD],args.model_config.n_dec_layer=2,args.model_config.n_enc_layer=2,args.model_config.n_head=4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded46d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discrete\n",
    "# [RANDOM,GOAL,ID,FD],args.model_config.n_dec_layer=1\n",
    "# path = \"/private/home/philippwu/mtm/outputs/mtm_mae/2022-11-18_22-20-17/1_+experiments=exorl_discrete_rew_qpos,args.mask_patterns=[RANDOM,GOAL,ID,FD],args.model_config.n_dec_layer=1,args.model_config.n_enc_layer=2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652d6e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discrete\n",
    "# [RANDOM,GOAL],args.model_config.n_dec_layer=1\n",
    "# path = \"/private/home/philippwu/mtm/outputs/mtm_mae/2022-11-18_22-20-17/4_+experiments=exorl_discrete_rew_qpos,args.mask_patterns=[RANDOM,GOAL],args.model_config.n_dec_layer=1,args.model_config.n_enc_layer=2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0ab135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discrete\n",
    "# [RANDOM,GOAL],args.model_config.n_dec_layer=2\n",
    "# path = \"/private/home/philippwu/mtm/outputs/mtm_mae/2022-11-18_22-20-17/4_+experiments=exorl_discrete_rew_qpos,args.mask_patterns=[RANDOM,GOAL],args.model_config.n_dec_layer=2,args.model_config.n_enc_layer=2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad27bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find checkpoints in the directory\n",
    "steps = []\n",
    "names = []\n",
    "paths_ = os.listdir(path)\n",
    "for name in [os.path.join(path, n) for n in paths_ if \"pt\" in n]:\n",
    "    step = os.path.basename(name).split(\"_\")[-1].split(\".\")[0]\n",
    "    steps.append(int(step))\n",
    "    names.append(name)\n",
    "    print(name)\n",
    "\n",
    "ckpt_path = names[np.argmax(steps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd54da7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt_path = '/private/home/philippwu/mtm/outputs/mtm_mae/2022-11-17_18-22-57/1_+experiments=exorl_continuous_rew_qpos,args.mask_patterns=[RANDOM,GOAL,ID,FD],args.model_config.n_dec_layer=1,args.model_config.n_enc_layer=1,args.model_config.n_head=4/model_640000.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2a185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.load(ckpt_path)[\"step\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1296438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hydra_cfg = OmegaConf.load(os.path.join(path, \".hydra/config.yaml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89589dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make datasets smaller for easier loading\n",
    "hydra_cfg.dataset.train_max_size = 10000\n",
    "hydra_cfg.dataset.val_max_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7da979",
   "metadata": {},
   "outputs": [],
   "source": [
    "del hydra_cfg.args.wandb_config\n",
    "cfg = hydra.utils.instantiate(hydra_cfg.args)\n",
    "pprint(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e6d55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = hydra.utils.call(\n",
    "    hydra_cfg.dataset, seq_steps=cfg.model_config.traj_length\n",
    ")\n",
    "print(\"Train set size =\", len(train_dataset))\n",
    "print(\"Validation set size =\", len(val_dataset))\n",
    "\n",
    "tokenizers: Dict[str, Tokenizer] = {\n",
    "    k: hydra.utils.call(v, key=k, train_dataset=train_dataset)\n",
    "    for k, v in hydra_cfg.tokenizers.items()\n",
    "}\n",
    "tokenizer_manager = TokenizerManager(tokenizers)\n",
    "discrete_map: Dict[str, bool] = {}\n",
    "for k, v in tokenizers.items():\n",
    "    discrete_map[k] = v.discrete\n",
    "print(tokenizers)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    # shuffle=True,\n",
    "    pin_memory=True,\n",
    "    batch_size=cfg.batch_size,\n",
    "    num_workers=cfg.n_workers,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    # shuffle=False,\n",
    "    batch_size=cfg.batch_size,\n",
    "    num_workers=cfg.n_workers,\n",
    ")\n",
    "train_batch = next(iter(train_loader))\n",
    "tokenized = tokenizer_manager.encode(train_batch)\n",
    "data_shapes = {}\n",
    "for k, v in tokenized.items():\n",
    "    data_shapes[k] = v.shape[-2:]\n",
    "print(data_shapes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34a10df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16073d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = val_dataset._env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fddc4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "image = env.physics.render(480, 640)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeb414b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f0807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_trajectory_with_metadata = val_dataset.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bdcc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_trajectory_with_metadata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcb2bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = 6\n",
    "state = sample_trajectory_with_metadata[\"physics\"][time]\n",
    "state0 = sample_trajectory_with_metadata[\"physics\"][0]\n",
    "#env.reset()\n",
    "with env.physics.reset_context():\n",
    "    env.physics.set_state(state)\n",
    "    \n",
    "obs = env.task.get_observation(env.physics)\n",
    "print(obs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11572655",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.physics.get_state()\n",
    "np.testing.assert_allclose(obs[\"orientations\"], sample_trajectory_with_metadata[\"observations\"][time][0:14])\n",
    "obs[\"orientations\"] - sample_trajectory_with_metadata[\"observations\"][time][0:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34826e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_trajectory_with_metadata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4a4614",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time)\n",
    "action = sample_trajectory_with_metadata[\"actions\"][time]\n",
    "new_obs = env.step(action)\n",
    "new_obs[\"observation\"] - sample_trajectory_with_metadata[\"observations\"][time + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea0049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.physics.get_state() - sample_trajectory_with_metadata[\"physics\"][time + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0c33fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = sample_trajectory_with_metadata[\"actions\"][time + 1]\n",
    "new_obs = env.step(action)\n",
    "new_obs[\"observation\"] - sample_trajectory_with_metadata[\"observations\"][time + 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6850634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set env physics\n",
    "env.reset()\n",
    "with env.physics.reset_context():\n",
    "    env.physics.set_state(sample_trajectory_with_metadata[\"physics\"][0])\n",
    "\n",
    "# rollout actions\n",
    "actions = sample_trajectory_with_metadata[\"actions\"]\n",
    "_obs = sample_trajectory_with_metadata[\"observations\"]\n",
    "images = [env.physics.render(480, 640, 0)]\n",
    "for idx, action in enumerate(actions):\n",
    "    obs = env.step(action)[\"observation\"]\n",
    "    image = env.physics.render(480, 640, 0)\n",
    "    if idx < len(actions) - 1:\n",
    "        np.testing.assert_allclose(obs, _obs[idx+1], 1e-1, 1e-1)\n",
    "    images.append(image)\n",
    "# media.show_video(images, fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8151a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba3a117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set env physics\n",
    "env.reset()\n",
    "with env.physics.reset_context():\n",
    "    env.physics.set_state(state0)\n",
    "\n",
    "# rollout actions\n",
    "actions = sample_trajectory_with_metadata[\"actions\"]\n",
    "_obs = sample_trajectory_with_metadata[\"observations\"]\n",
    "images_gt = [env.physics.render(480, 640, 0)]\n",
    "for idx, p in enumerate(sample_trajectory_with_metadata[\"physics\"]):\n",
    "    env.physics.reset()\n",
    "    with env.physics.reset_context():\n",
    "        env.physics.set_state(p)\n",
    "    image = env.physics.render(480, 640, 0)\n",
    "    images_gt.append(image)\n",
    "\n",
    "media.show_video(images_gt, fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d921571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lie_back = [ -1.2 ,  0. ,  -1.57,  0, 0. , 0.0, 0, -0.,  0.0]\n",
    "lie_front = [-1.2, -0, 1.57, 0, 0, 0, 0, 0., 0.]\n",
    "legs_up = [ -1.24 ,  0. ,  -1.57,  1.57, 0. , 0.0,  1.57, -0.,  0.0]\n",
    "\n",
    "kneel = [ -0.5 ,  0. ,  0,  0, -1.57, -0.8,  1.57, -1.57,  0.0]\n",
    "side_angle = [ -0.3 ,  0. ,  0.9,  0, 0, -0.7,  1.87, -1.07,  0.0]\n",
    "stand_up = [-0.15, 0., 0.34, 0.74, -1.34, -0., 1.1, -0.66, -0.1]\n",
    "\n",
    "lean_back = [-0.27, 0., -0.45, 0.22, -1.5, 0.86, 0.6, -0.8, -0.4]\n",
    "boat = [ -1.04 ,  0. ,  -0.8,  1.6, 0. , 0.0, 1.6, -0.,  0.0]\n",
    "bridge = [-1.1, 0., -2.2, -0.3, -1.5, 0., -0.3, -0.8, -0.4]\n",
    "\n",
    "head_stand = [-1, 0., -3, 0.6, -1, -0.3, 0.9, -0.5, 0.3]\n",
    "one_feet = [-0.2, 0., 0, 0.7, -1.34, 0.5, 1.5, -0.6, 0.1]\n",
    "arabesque = [-0.34, 0., 1.57, 1.57, 0, 0., 0, -0., 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c40192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.physics.data.qpos = boat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78c39a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.physics.forward()\n",
    "phy_state = env.physics.get_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b5270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = Path(\"files/yoga\")\n",
    "folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef835530",
   "metadata": {},
   "outputs": [],
   "source": [
    "_img= env.physics.render(480, 640, 0)\n",
    "media.write_image(folder / \"goal.png\", _img)\n",
    "plt.imshow(_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87f5adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = list(env.task.get_observation(env.physics).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a54a532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = np.concatenate([values[0], np.array([values[1]]), values[2]])\n",
    "state = np.concatenate([values[0], np.array([values[1]])])\n",
    "goal_state = state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07f8ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_len = cfg.model_config.traj_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7ea4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "state[None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015bac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_states  = torch.from_numpy(state[None]).repeat(t_len, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5603f458",
   "metadata": {},
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f00bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MaskedDP(data_shapes, cfg.model_config)\n",
    "model.to(cfg.device)\n",
    "model.train()\n",
    "\n",
    "# load weights\n",
    "model.load_state_dict(torch.load(ckpt_path)[\"model\"])\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1082725",
   "metadata": {},
   "outputs": [],
   "source": [
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309a4853",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230568bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_torch = {\n",
    "    \"states\": torch_states.to(cfg.device, torch.float32).unsqueeze(0),\n",
    "    \"actions\": torch.from_numpy(sample_trajectory_with_metadata[\"actions\"])\n",
    "    .to(cfg.device)\n",
    "    .unsqueeze(0),\n",
    "}\n",
    "\n",
    "\n",
    "# goalreaching mask\n",
    "prediction_steps = t_len-1\n",
    "state_mask = torch.ones(batch_torch[\"states\"].shape[1])\n",
    "action_mask = torch.zeros(batch_torch[\"actions\"].shape[1])\n",
    "masks = {\"states\": state_mask, \"actions\": action_mask}\n",
    "masks_torch = {k: v.to(cfg.device) for k, v in masks.items()}\n",
    "\n",
    "\n",
    "# #shorten everything to the prediction_steps\n",
    "# for k in masks.keys():\n",
    "#     masks_torch[k] = masks_torch[k][:prediction_steps+1]\n",
    "#     batch_torch[k] = batch_torch[k][:prediction_steps+1]\n",
    "\n",
    "encoded_batch = tokenizer_manager.encode(batch_torch)\n",
    "predicted_trajectories = model(encoded_batch, masks_torch)\n",
    "decoded_trajectories = tokenizer_manager.decode(predicted_trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bca8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c9df3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_actions():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba55caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "with env.physics.reset_context():\n",
    "    env.physics.set_state(phy_state)\n",
    "    \n",
    "images_open_loop = [env.physics.render(480, 640, 0)]\n",
    "execute_actions = decoded_trajectories[\"actions\"].squeeze(0).detach().cpu().numpy()\n",
    "traj_real_ol = defaultdict(list)\n",
    "traj_real_ol[\"states\"].append(goal_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1611fecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, action in enumerate(execute_actions):\n",
    "    traj_real_ol[\"actions\"].append(action)\n",
    "    obs = env.step(action)\n",
    "    traj_real_ol[\"states\"].append(obs[\"observation\"][:15])\n",
    "    image = env.physics.render(480, 640, 0)\n",
    "    images_open_loop.append(image)\n",
    "    \n",
    "traj_real_ol[\"states\"] = traj_real_ol[\"states\"][:-1]\n",
    "    # compare obs against data\n",
    "#     _obs = sample_trajectory_with_metadata[\"observations\"]\n",
    "#     np.testing.assert_allclose(obs, _obs[idx], atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb395e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf = np.array(images_open_loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b54954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40da4c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "media.show_video(images_open_loop, fps=30)\n",
    "media.write_video(folder / \"open_loop.gif\", np.array(images_open_loop), codec='gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cc4731",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_n_plots = 3\n",
    "for k, _ in decoded_trajectories.items():\n",
    "    traj = batch_torch[k][0].detach().cpu().numpy()\n",
    "    pred_traj = decoded_trajectories[k][0].detach().cpu().numpy()\n",
    "    mask = masks[k]\n",
    "    for i in range(min(max_n_plots, traj.shape[-1])):\n",
    "        gt_i = traj[:, i]\n",
    "        re_i = pred_traj[:, i]\n",
    "        real_i = np.array(traj_real_ol[k])[:, i]\n",
    "        if len(mask.shape) == 1:\n",
    "            # only along time dimension: repeat across the given dimension\n",
    "            mask = mask[:, None].repeat(1, traj.shape[1])\n",
    "        select_mask = mask[:, i].cpu().numpy()\n",
    "        unmasked_gt_i = gt_i[select_mask == 1]\n",
    "        unmasked_gt_i_index = np.arange(len(gt_i))[select_mask == 1]\n",
    "        vmax = max(np.max(gt_i), np.max(re_i), np.max(real_i))\n",
    "        vmin = min(np.min(gt_i), np.min(re_i), np.min(real_i))\n",
    "        y_range = vmax - vmin\n",
    "        with ph.plot_context() as (fig, ax):\n",
    "\n",
    "            ax.plot(gt_i, \"-o\", label=\"ground truth\")\n",
    "            ax.plot(\n",
    "                re_i, \"-o\", label=\"reconstructed\", markerfacecolor=\"none\"\n",
    "            )\n",
    "            ax.plot(\n",
    "                unmasked_gt_i_index,\n",
    "                unmasked_gt_i,\n",
    "                \"o\",\n",
    "                label=\"unmasked ground truth\",\n",
    "            )\n",
    "            ax.plot(\n",
    "                real_i, \".\", label=\"real\"\n",
    "            )\n",
    "            ax.set_ylim(\n",
    "                vmin - y_range / 5,\n",
    "                vmax + y_range / 5,\n",
    "            )\n",
    "            ax.legend()\n",
    "            ax.set_title(f\"{k}_{i}\")\n",
    "            plt.show()\n",
    "#             eval_logs[\n",
    "#                 f\"{eval_name}/batch={batch_idx}|{i}_{k}\"\n",
    "#             ] = wandb.Image(ph.plot_as_image(fig))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2321cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run closed loop\n",
    "batch_torch = {\n",
    "    \"states\": torch_states.to(cfg.device, torch.float32).unsqueeze(0),\n",
    "    \"actions\": torch.from_numpy(sample_trajectory_with_metadata[\"actions\"])\n",
    "    .to(cfg.device)\n",
    "    .unsqueeze(0),\n",
    "}\n",
    "\n",
    "\n",
    "# goalreaching mask\n",
    "state_mask = torch.ones(batch_torch[\"states\"].shape[1])\n",
    "action_mask = torch.zeros(batch_torch[\"actions\"].shape[1])\n",
    "masks = {\"states\": state_mask, \"actions\": action_mask}\n",
    "masks_torch = {k: v.to(cfg.device) for k, v in masks.items()}\n",
    "\n",
    "# #shorten everything to the prediction_steps\n",
    "# for k in masks.keys():\n",
    "#     masks_torch[k] = masks_torch[k][:prediction_steps+1]\n",
    "#     batch_torch[k] = batch_torch[k][:prediction_steps+1]\n",
    "\n",
    "env.reset()\n",
    "with env.physics.reset_context():\n",
    "    env.physics.set_state(phy_state)\n",
    "\n",
    "images_close_loop = [env.physics.render(480, 640, 0)]\n",
    "traj_real_cl = defaultdict(list)\n",
    "traj_real_cl[\"states\"].append(goal_state)\n",
    "\n",
    "\n",
    "for i in range(prediction_steps):\n",
    "    encoded_batch = tokenizer_manager.encode(batch_torch)\n",
    "    predicted_trajectories = model(encoded_batch, masks_torch)\n",
    "    decoded_trajectories = tokenizer_manager.decode(predicted_trajectories)\n",
    "    \n",
    "    a = decoded_trajectories[\"actions\"][0][i].detach().cpu().numpy()\n",
    "    batch_torch[\"actions\"][0][i] = torch.tensor(a, device=\"cuda\")\n",
    "    traj_real_cl[\"actions\"].append(a)\n",
    "    time_step = env.step(a)\n",
    "    traj_real_cl[\"states\"].append(time_step[\"observation\"][:15])\n",
    "    image = env.physics.render(480, 640, 0)\n",
    "    images_close_loop.append(image)\n",
    "    masks[\"states\"][i] = 1\n",
    "    masks[\"actions\"][i] = 1\n",
    "    batch_torch[\"states\"][0][i] = torch.tensor(time_step[\"observation\"][:15], device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d44e3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "media.show_video(images_close_loop, fps=30)\n",
    "media.write_video(folder / \"close_loop.gif\", images_close_loop, fps=30, codec='gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64531e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(traj_real_cl[k])[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c7680a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_n_plots = 3\n",
    "for k, _ in decoded_trajectories.items():\n",
    "    traj = torch_states.numpy()\n",
    "    pred_traj = decoded_trajectories[k][0].detach().cpu().numpy()\n",
    "    mask = masks[k]\n",
    "    for i in range(min(max_n_plots, traj.shape[-1])):\n",
    "        gt_i = traj[:, i]\n",
    "        re_i = pred_traj[:, i]\n",
    "        real_i = np.array(traj_real_cl[k])[:, i]\n",
    "        if len(mask.shape) == 1:\n",
    "            # only along time dimension: repeat across the given dimension\n",
    "            mask = mask[:, None].repeat(1, traj.shape[1])\n",
    "        select_mask = mask[:, i].cpu().numpy()\n",
    "        unmasked_gt_i = gt_i[select_mask == 1]\n",
    "        unmasked_gt_i_index = np.arange(len(gt_i))[select_mask == 1]\n",
    "        vmax = max(np.max(gt_i), np.max(re_i))\n",
    "        vmin = min(np.min(gt_i), np.min(re_i))\n",
    "        y_range = vmax - vmin\n",
    "        with ph.plot_context() as (fig, ax):\n",
    "\n",
    "            ax.plot(gt_i, \"-o\", label=\"ground truth\")\n",
    "            ax.plot(\n",
    "                re_i, \"-o\", label=\"reconstructed\", markerfacecolor=\"none\"\n",
    "            )\n",
    "            ax.plot(\n",
    "                unmasked_gt_i_index,\n",
    "                unmasked_gt_i,\n",
    "                \"o\",\n",
    "                label=\"unmasked ground truth\",\n",
    "            )\n",
    "            ax.plot(\n",
    "                real_i, \".\", label=\"real\"\n",
    "            )\n",
    "            ax.set_ylim(\n",
    "                vmin - y_range / 5,\n",
    "                vmax + y_range / 5,\n",
    "            )\n",
    "            ax.legend()\n",
    "            ax.set_title(f\"{k}_{i}\")\n",
    "            plt.show()\n",
    "#             eval_logs[\n",
    "#                 f\"{eval_name}/batch={batch_idx}|{i}_{k}\"\n",
    "#             ] = wandb.Image(ph.plot_as_image(fig))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02232f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_cl = goal_state - traj_real_cl[\"states\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2049c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(diff_cl**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218fbaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_ol = goal_state - traj_real_ol[\"states\"][-1][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff5b18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(diff_ol**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4813eca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a9f2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run closed loop\n",
    "batch_torch = {\n",
    "    \"states\": torch_states.to(cfg.device, torch.float32).unsqueeze(0),\n",
    "    \"actions\": torch.from_numpy(sample_trajectory_with_metadata[\"actions\"])\n",
    "    .to(cfg.device)\n",
    "    .unsqueeze(0),\n",
    "}\n",
    "\n",
    "\n",
    "# goalreaching mask\n",
    "state_mask = torch.zeros(batch_torch[\"states\"].shape[1])\n",
    "state_mask[:3] = 1\n",
    "state_mask[-3:] = 1\n",
    "action_mask = torch.zeros(batch_torch[\"actions\"].shape[1])\n",
    "masks = {\"states\": state_mask, \"actions\": action_mask}\n",
    "masks_torch = {k: v.to(cfg.device) for k, v in masks.items()}\n",
    "\n",
    "# #shorten everything to the prediction_steps\n",
    "# for k in masks.keys():\n",
    "#     masks_torch[k] = masks_torch[k][:prediction_steps+1]\n",
    "#     batch_torch[k] = batch_torch[k][:prediction_steps+1]\n",
    "\n",
    "env.reset()\n",
    "with env.physics.reset_context():\n",
    "    env.physics.set_state(phy_state)\n",
    "\n",
    "images_close_loop = [env.physics.render(480, 640, 0)]\n",
    "traj_real_cl = defaultdict(list)\n",
    "traj_real_cl[\"states\"].append(sample_trajectory_with_metadata[\"observations\"][0][:15])\n",
    "\n",
    "    \n",
    "\n",
    "for i in range(prediction_steps):\n",
    "    encoded_batch = tokenizer_manager.encode(batch_torch)\n",
    "    predicted_trajectories = model(encoded_batch, masks_torch)\n",
    "    decoded_trajectories = tokenizer_manager.decode(predicted_trajectories)\n",
    "    \n",
    "    a = decoded_trajectories[\"actions\"][0][i].detach().cpu().numpy()\n",
    "    batch_torch[\"actions\"][0][i] = torch.tensor(a, device=\"cuda\")\n",
    "    traj_real_cl[\"actions\"].append(a)\n",
    "    time_step = env.step(a)\n",
    "    traj_real_cl[\"states\"].append(time_step[\"observation\"][:15])\n",
    "    image = env.physics.render(480, 640, 0)\n",
    "    images_close_loop.append(image)\n",
    "    masks[\"states\"][i] = 1\n",
    "    masks[\"actions\"][i] = 1\n",
    "    batch_torch[\"states\"][0][i] = torch.tensor(time_step[\"observation\"][:15], device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef43500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "media.show_video(images_close_loop, fps=30)\n",
    "media.write_video(folder / \"close_loop_goal.gif\", images_close_loop, fps=30, codec='gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77c602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_n_plots = 3\n",
    "for k, _ in decoded_trajectories.items():\n",
    "    traj = torch_states.numpy()\n",
    "    pred_traj = decoded_trajectories[k][0].detach().cpu().numpy()\n",
    "    mask = masks[k]\n",
    "    for i in range(min(max_n_plots, traj.shape[-1])):\n",
    "        gt_i = traj[:, i]\n",
    "        re_i = pred_traj[:, i]\n",
    "        real_i = np.array(traj_real_cl[k])[:, i]\n",
    "        if len(mask.shape) == 1:\n",
    "            # only along time dimension: repeat across the given dimension\n",
    "            mask = mask[:, None].repeat(1, traj.shape[1])\n",
    "        select_mask = mask[:, i].cpu().numpy()\n",
    "        unmasked_gt_i = gt_i[select_mask == 1]\n",
    "        unmasked_gt_i_index = np.arange(len(gt_i))[select_mask == 1]\n",
    "        vmax = max(np.max(gt_i), np.max(re_i))\n",
    "        vmin = min(np.min(gt_i), np.min(re_i))\n",
    "        y_range = vmax - vmin\n",
    "        with ph.plot_context() as (fig, ax):\n",
    "\n",
    "            ax.plot(gt_i, \"-o\", label=\"ground truth\")\n",
    "            ax.plot(\n",
    "                re_i, \"-o\", label=\"reconstructed\", markerfacecolor=\"none\"\n",
    "            )\n",
    "            ax.plot(\n",
    "                unmasked_gt_i_index,\n",
    "                unmasked_gt_i,\n",
    "                \"o\",\n",
    "                label=\"unmasked ground truth\",\n",
    "            )\n",
    "            ax.plot(\n",
    "                real_i, \".\", label=\"real\"\n",
    "            )\n",
    "            ax.set_ylim(\n",
    "                vmin - y_range / 5,\n",
    "                vmax + y_range / 5,\n",
    "            )\n",
    "            ax.legend()\n",
    "            ax.set_title(f\"{k}_{i}\")\n",
    "            plt.show()\n",
    "#             eval_logs[\n",
    "#                 f\"{eval_name}/batch={batch_idx}|{i}_{k}\"\n",
    "#             ] = wandb.Image(ph.plot_as_image(fig))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b591895d",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_cl = goal_state - traj_real_cl[\"states\"][-1]\n",
    "np.sum(diff_cl**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22dfb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_reach_states = torch_states.clone()\n",
    "loc = 0\n",
    "goal_reach_states[:3] = torch.tensor(sample_trajectory_with_metadata[\"observations\"][loc:loc+3, :15])\n",
    "physics_start = sample_trajectory_with_metadata[\"physics\"][loc]\n",
    "alpha = torch.linspace(0, 1, t_len)\n",
    "goal_reach_states = goal_reach_states[0] + (goal_reach_states[-1] - goal_reach_states[0]) * alpha[:, None]\n",
    "\n",
    "\n",
    "# run closed loop\n",
    "batch_torch = {\n",
    "    \"states\": goal_reach_states.to(cfg.device, torch.float32).unsqueeze(0),\n",
    "    \"actions\": torch.from_numpy(sample_trajectory_with_metadata[\"actions\"])\n",
    "    .to(cfg.device)\n",
    "    .unsqueeze(0),\n",
    "}\n",
    "\n",
    "\n",
    "# goalreaching mask\n",
    "state_mask = torch.zeros(batch_torch[\"states\"].shape[1])\n",
    "state_mask[:3] = 1\n",
    "state_mask[-3:] = 1\n",
    "action_mask = torch.zeros(batch_torch[\"actions\"].shape[1])\n",
    "masks = {\"states\": state_mask, \"actions\": action_mask}\n",
    "masks_torch = {k: v.to(cfg.device) for k, v in masks.items()}\n",
    "\n",
    "encoded_batch = tokenizer_manager.encode(batch_torch)\n",
    "predicted_trajectories = model(encoded_batch, masks_torch)\n",
    "decoded_trajectories = tokenizer_manager.decode(predicted_trajectories)\n",
    "\n",
    "env.reset()\n",
    "with env.physics.reset_context():\n",
    "    env.physics.set_state(physics_start)\n",
    "\n",
    "images_close_loop = [env.physics.render(480, 640, 0)]\n",
    "execute_actions = decoded_trajectories[\"actions\"].squeeze(0).detach().cpu().numpy()\n",
    "traj_real_cl = defaultdict(list)\n",
    "traj_real_cl[\"states\"].append(sample_trajectory_with_metadata[\"observations\"][0][:15])\n",
    "\n",
    "\n",
    "\n",
    "for idx, action in enumerate(execute_actions):\n",
    "    traj_real_cl[\"actions\"].append(action)\n",
    "    obs = env.step(action)\n",
    "    traj_real_cl[\"states\"].append(obs[\"observation\"][:15])\n",
    "    image = env.physics.render(480, 640, 0)\n",
    "    images_close_loop.append(image)\n",
    "    \n",
    "traj_real_cl[\"states\"] = traj_real_cl[\"states\"][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e798e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a21b66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "media.show_video(images_close_loop, fps=30)\n",
    "media.write_video(folder / \"open_loop_reach_from_random.gif\", images_close_loop, fps=30, codec='gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7606cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_n_plots = 3\n",
    "for k, _ in decoded_trajectories.items():\n",
    "    traj = goal_reach_states.numpy()\n",
    "    pred_traj = decoded_trajectories[k][0].detach().cpu().numpy()\n",
    "    mask = masks[k]\n",
    "    for i in range(min(max_n_plots, traj.shape[-1])):\n",
    "        gt_i = traj[:, i]\n",
    "        re_i = pred_traj[:, i]\n",
    "        real_i = np.array(traj_real_cl[k])[:, i]\n",
    "        if len(mask.shape) == 1:\n",
    "            # only along time dimension: repeat across the given dimension\n",
    "            mask = mask[:, None].repeat(1, traj.shape[1])\n",
    "        select_mask = mask[:, i].cpu().numpy()\n",
    "        unmasked_gt_i = gt_i[select_mask == 1]\n",
    "        unmasked_gt_i_index = np.arange(len(gt_i))[select_mask == 1]\n",
    "        vmax = max(np.max(gt_i), np.max(re_i))\n",
    "        vmin = min(np.min(gt_i), np.min(re_i))\n",
    "        y_range = vmax - vmin\n",
    "        with ph.plot_context() as (fig, ax):\n",
    "\n",
    "            ax.plot(gt_i, \"-o\", label=\"ground truth\")\n",
    "            ax.plot(\n",
    "                re_i, \"-o\", label=\"reconstructed\", markerfacecolor=\"none\"\n",
    "            )\n",
    "            ax.plot(\n",
    "                unmasked_gt_i_index,\n",
    "                unmasked_gt_i,\n",
    "                \"o\",\n",
    "                label=\"unmasked ground truth\",\n",
    "            )\n",
    "            ax.plot(\n",
    "                real_i, \".\", label=\"real\"\n",
    "            )\n",
    "            ax.set_ylim(\n",
    "                vmin - y_range / 5,\n",
    "                vmax + y_range / 5,\n",
    "            )\n",
    "            ax.legend()\n",
    "            ax.set_title(f\"{k}_{i}\")\n",
    "            plt.show()\n",
    "#             eval_logs[\n",
    "#                 f\"{eval_name}/batch={batch_idx}|{i}_{k}\"\n",
    "#             ] = wandb.Image(ph.plot_as_image(fig))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fe7973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e741117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_reach_states = torch_states.clone()\n",
    "loc = 20\n",
    "goal_reach_states[:3] = torch.tensor(sample_trajectory_with_metadata[\"observations\"][loc:loc+3, :15])\n",
    "physics_start = sample_trajectory_with_metadata[\"physics\"][loc]\n",
    "alpha = torch.linspace(0, 1, t_len)\n",
    "goal_reach_states = goal_reach_states[0] + (goal_reach_states[-1] - goal_reach_states[0]) * alpha[:, None]\n",
    "\n",
    "\n",
    "# run closed loop\n",
    "batch_torch = {\n",
    "    \"states\": goal_reach_states.to(cfg.device, torch.float32).unsqueeze(0),\n",
    "    \"actions\": torch.from_numpy(sample_trajectory_with_metadata[\"actions\"])\n",
    "    .to(cfg.device)\n",
    "    .unsqueeze(0),\n",
    "}\n",
    "\n",
    "\n",
    "# goalreaching mask\n",
    "state_mask = torch.zeros(batch_torch[\"states\"].shape[1])\n",
    "state_mask[:3] = 1\n",
    "state_mask[-3:] = 1\n",
    "action_mask = torch.zeros(batch_torch[\"actions\"].shape[1])\n",
    "masks = {\"states\": state_mask, \"actions\": action_mask}\n",
    "masks_torch = {k: v.to(cfg.device) for k, v in masks.items()}\n",
    "\n",
    "encoded_batch = tokenizer_manager.encode(batch_torch)\n",
    "predicted_trajectories = model(encoded_batch, masks_torch)\n",
    "decoded_trajectories = tokenizer_manager.decode(predicted_trajectories)\n",
    "\n",
    "env.reset()\n",
    "with env.physics.reset_context():\n",
    "    env.physics.set_state(physics_start)\n",
    "\n",
    "images_close_loop = [env.physics.render(480, 640, 0)]\n",
    "traj_real_cl = defaultdict(list)\n",
    "traj_real_cl[\"states\"].append(sample_trajectory_with_metadata[\"observations\"][0][:15])\n",
    "\n",
    "for i in range(prediction_steps):\n",
    "    encoded_batch = tokenizer_manager.encode(batch_torch)\n",
    "    predicted_trajectories = model(encoded_batch, masks_torch)\n",
    "    decoded_trajectories = tokenizer_manager.decode(predicted_trajectories)\n",
    "    \n",
    "    a = decoded_trajectories[\"actions\"][0][i].detach().cpu().numpy()\n",
    "    batch_torch[\"actions\"][0][i] = torch.tensor(a, device=\"cuda\")\n",
    "    traj_real_cl[\"actions\"].append(a)\n",
    "    time_step = env.step(a)\n",
    "    traj_real_cl[\"states\"].append(time_step[\"observation\"][:15])\n",
    "    image = env.physics.render(480, 640, 0)\n",
    "    images_close_loop.append(image)\n",
    "    masks[\"states\"][i] = 1\n",
    "    masks[\"actions\"][i] = 1\n",
    "    batch_torch[\"states\"][0][i] = torch.tensor(time_step[\"observation\"][:15], device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8c8887",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_n_plots = 3\n",
    "for k, _ in decoded_trajectories.items():\n",
    "    traj = goal_reach_states.numpy()\n",
    "    pred_traj = decoded_trajectories[k][0].detach().cpu().numpy()\n",
    "    mask = masks[k]\n",
    "    for i in range(min(max_n_plots, traj.shape[-1])):\n",
    "        gt_i = traj[:, i]\n",
    "        re_i = pred_traj[:, i]\n",
    "        real_i = np.array(traj_real_cl[k])[:, i]\n",
    "        if len(mask.shape) == 1:\n",
    "            # only along time dimension: repeat across the given dimension\n",
    "            mask = mask[:, None].repeat(1, traj.shape[1])\n",
    "        select_mask = mask[:, i].cpu().numpy()\n",
    "        unmasked_gt_i = gt_i[select_mask == 1]\n",
    "        unmasked_gt_i_index = np.arange(len(gt_i))[select_mask == 1]\n",
    "        vmax = max(np.max(gt_i), np.max(re_i))\n",
    "        vmin = min(np.min(gt_i), np.min(re_i))\n",
    "        y_range = vmax - vmin\n",
    "        with ph.plot_context() as (fig, ax):\n",
    "\n",
    "            ax.plot(gt_i, \"-o\", label=\"ground truth\")\n",
    "            ax.plot(\n",
    "                re_i, \"-o\", label=\"reconstructed\", markerfacecolor=\"none\"\n",
    "            )\n",
    "            ax.plot(\n",
    "                unmasked_gt_i_index,\n",
    "                unmasked_gt_i,\n",
    "                \"o\",\n",
    "                label=\"unmasked ground truth\",\n",
    "            )\n",
    "            ax.plot(\n",
    "                real_i, \".\", label=\"real\"\n",
    "            )\n",
    "            ax.set_ylim(\n",
    "                vmin - y_range / 5,\n",
    "                vmax + y_range / 5,\n",
    "            )\n",
    "            ax.legend()\n",
    "            ax.set_title(f\"{k}_{i}\")\n",
    "            plt.show()\n",
    "#             eval_logs[\n",
    "#                 f\"{eval_name}/batch={batch_idx}|{i}_{k}\"\n",
    "#             ] = wandb.Image(ph.plot_as_image(fig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76058d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "media.show_video(images_close_loop, fps=30)\n",
    "media.write_video(folder / \"closed_loop_reach_from_random.gif\", images_close_loop, fps=30, codec='gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d28eae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
