{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1ba950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MUJOCO_GL\"] = \"egl\"\n",
    "    \n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Callable, Dict, Tuple\n",
    "from pprint import pprint\n",
    "\n",
    "import dcargs\n",
    "import glob\n",
    "import hydra\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from research.logger import WandBLogger, WandBLoggerConfig\n",
    "from research.mtm.models.mtm_model import MaskedDP, MTMConfig, make_plots_with_masks\n",
    "from research.mtm.tokenizers.base import Tokenizer, TokenizerManager\n",
    "import mediapy as media\n",
    "from research.mtm.train import RunConfig\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from research.utils.plot_utils import PlotHandler as ph\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0ab135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discrete\n",
    "# path = \"/private/home/philippwu/mtm/outputs/mtm_mae/2022-11-26_11-54-07/1_+experiments=yoga_discrete,args.mask_patterns=[RANDOM,GOAL,ID,FD]\"\n",
    "# path = \"/private/home/philippwu/mtm/outputs/mtm_mae/2022-11-27_01-26-57/13_+experiments=yoga_discrete,args.mask_patterns=[GOAL]\"\n",
    "# path = \"/private/home/philippwu/mtm/outputs/mtm_mae/2022-12-09_10-17-52/4_+experiments=yoga_discrete,args.learning_rate=0.0003,args.mask_patterns=[RANDOM,GOAL],args.weight_decay=0.001\"\n",
    "# path = \"/private/home/philippwu/mtm/outputs/mtm_mae/2022-12-09_11-13-11/4_+experiments=yoga_discrete,args.learning_rate=0.0003,args.mask_patterns=[FULL_RANDOM,RANDOM,GOAL],args.weight_decay=0.001\"\n",
    "path = \"/private/home/philippwu/mtm/outputs/mtm_mae/2022-12-09_11-13-11/9_+experiments=yoga_discrete,args.learning_rate=0.0003,args.mask_patterns=[FULL_RANDOM,RANDOM,GOAL,GOAL_N,ID,FD],args.weight_decay=0.001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12a90b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"/private/home/philippwu/mtm/outputs/mtm_mae/2022-11-27_01-26-57/19_+experiments=yoga_discrete,args.mask_patterns=[RANDOM,GOAL,GOAL_N,ID,FD]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910ae559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cont\n",
    "# path = \"/private/home/philippwu/mtm/outputs/mtm_mae/2022-11-29_07-28-03/1_+experiments=yoga_cont,args.mask_patterns=[RANDOM,GOAL,ID,FD]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0209b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # cont goal reaching\n",
    "# path = \"/private/home/philippwu/mtm/outputs/mtm_mae/2022-11-29_07-28-03/9_+experiments=yoga_cont,args.mask_patterns=[RANDOM,GOAL,GOAL_N,ID,FD]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f770f9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"/private/home/philippwu/mtm/outputs/mtm_mae/2022-11-29_07-28-03/3_+experiments=yoga_cont,args.mask_patterns=[GOAL]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba26c51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all, actions only\n",
    "# path = \"/private/home/philippwu/mtm/outputs/mtm_mae/2022-11-27_01-26-31/29_+experiments2=yoga_discrete_actions,args.mask_patterns=[RANDOM,GOAL,GOAL_N,ID,FD]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246a9577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all except goal_all, actions only\n",
    "# path = \"/private/home/philippwu/mtm/outputs/mtm_mae/2022-11-27_01-26-31/21_+experiments2=yoga_discrete_actions,args.mask_patterns=[RANDOM,GOAL,ID,FD]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38512598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # with full random\n",
    "# path = \"/private/home/philippwu/mtm/outputs/mtm_mae/2022-12-02_15-24-55/9_+experiments=yoga_discrete,args.mask_patterns=[FULL_RANDOM,RANDOM,GOAL,GOAL_N,ID,FD]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba80bbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # with full random\n",
    "# path = \"/private/home/philippwu/mtm/outputs/mtm_mae/2022-12-02_15-24-55/9_+experiments=yoga_discrete,args.mask_patterns=[FULL_RANDOM,RANDOM,GOAL,GOAL_N,ID,FD]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad27bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find checkpoints in the directory\n",
    "steps = []\n",
    "names = []\n",
    "paths_ = os.listdir(path)\n",
    "for name in [os.path.join(path, n) for n in paths_ if \"pt\" in n]:\n",
    "    step = os.path.basename(name).split(\"_\")[-1].split(\".\")[0]\n",
    "    steps.append(int(step))\n",
    "    names.append(name)\n",
    "    print(name)\n",
    "\n",
    "ckpt_path = names[np.argmax(steps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd54da7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt_path = '/private/home/philippwu/mtm/outputs/mtm_mae/2022-11-17_18-22-57/1_+experiments=exorl_continuous_rew_qpos,args.mask_patterns=[RANDOM,GOAL,ID,FD],args.model_config.n_dec_layer=1,args.model_config.n_enc_layer=1,args.model_config.n_head=4/model_640000.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44562698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c41418b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2a185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.load(ckpt_path)[\"step\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1296438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hydra_cfg = OmegaConf.load(os.path.join(path, \".hydra/config.yaml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41892c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hydra_cfg.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89589dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make datasets smaller for easier loading\n",
    "hydra_cfg.dataset.train_max_size = 10000000\n",
    "hydra_cfg.dataset.val_max_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7da979",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = hydra.utils.instantiate(hydra_cfg.args)\n",
    "pprint(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e6d55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = hydra.utils.call(\n",
    "    hydra_cfg.dataset, seq_steps=cfg.model_config.traj_length\n",
    ")\n",
    "print(\"Train set size =\", len(train_dataset))\n",
    "print(\"Validation set size =\", len(val_dataset))\n",
    "\n",
    "tokenizers: Dict[str, Tokenizer] = {\n",
    "    k: hydra.utils.call(v, key=k, train_dataset=train_dataset)\n",
    "    for k, v in hydra_cfg.tokenizers.items()\n",
    "}\n",
    "tokenizer_manager = TokenizerManager(tokenizers)\n",
    "discrete_map: Dict[str, bool] = {}\n",
    "for k, v in tokenizers.items():\n",
    "    discrete_map[k] = v.discrete\n",
    "print(tokenizers)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    # shuffle=True,\n",
    "    pin_memory=True,\n",
    "    batch_size=cfg.batch_size,\n",
    "    num_workers=cfg.n_workers,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    # shuffle=False,\n",
    "    batch_size=cfg.batch_size,\n",
    "    num_workers=cfg.n_workers,\n",
    ")\n",
    "train_batch = next(iter(train_loader))\n",
    "tokenized = tokenizer_manager.encode(train_batch)\n",
    "data_shapes = {}\n",
    "for k, v in tokenized.items():\n",
    "    data_shapes[k] = v.shape[-2:]\n",
    "print(data_shapes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34a10df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16073d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = val_dataset._env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fddc4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "image = env.physics.render(480, 640)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeb414b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f0807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_trajectory_with_metadata = val_dataset.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bdcc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_trajectory_with_metadata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcb2bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = 6\n",
    "state = sample_trajectory_with_metadata[\"physics\"][time]\n",
    "state0 = sample_trajectory_with_metadata[\"physics\"][0]\n",
    "#env.reset()\n",
    "with env.physics.reset_context():\n",
    "    env.physics.set_state(state)\n",
    "    \n",
    "obs = env.task.get_observation(env.physics)\n",
    "print(obs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11572655",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.physics.get_state()\n",
    "np.testing.assert_allclose(obs[\"orientations\"], sample_trajectory_with_metadata[\"observations\"][time][0:14])\n",
    "obs[\"orientations\"] - sample_trajectory_with_metadata[\"observations\"][time][0:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34826e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_trajectory_with_metadata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4a4614",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time)\n",
    "action = sample_trajectory_with_metadata[\"actions\"][time]\n",
    "new_obs = env.step(action)[0]\n",
    "new_obs - sample_trajectory_with_metadata[\"observations\"][time + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea0049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.physics.get_state() - sample_trajectory_with_metadata[\"physics\"][time + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0c33fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = sample_trajectory_with_metadata[\"actions\"][time + 1]\n",
    "new_obs = env.step(action)[0]\n",
    "new_obs - sample_trajectory_with_metadata[\"observations\"][time + 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6850634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set env physics\n",
    "env.reset()\n",
    "with env.physics.reset_context():\n",
    "    env.physics.set_state(sample_trajectory_with_metadata[\"physics\"][0])\n",
    "\n",
    "# rollout actions\n",
    "actions = sample_trajectory_with_metadata[\"actions\"]\n",
    "_obs = sample_trajectory_with_metadata[\"observations\"]\n",
    "images = [env.physics.render(480, 640, 0)]\n",
    "for idx, action in enumerate(actions):\n",
    "    obs = env.step(action)[0]\n",
    "    image = env.physics.render(480, 640, 0)\n",
    "    if idx < len(actions) - 1:\n",
    "        np.testing.assert_allclose(obs, _obs[idx+1], 1e-1, 1e-1)\n",
    "    images.append(image)\n",
    "# media.show_video(images, fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d921571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lie_back = [ -1.2 ,  0. ,  -1.57,  0, 0. , 0.0, 0, -0.,  0.0]\n",
    "lie_front = [-1.2, -0, 1.57, 0, 0, 0, 0, 0., 0.]\n",
    "legs_up = [ -1.24 ,  0. ,  -1.57,  1.57, 0. , 0.0,  1.57, -0.,  0.0]\n",
    "\n",
    "kneel = [ -0.5 ,  0. ,  0,  0, -1.57, -0.8,  1.57, -1.57,  0.0]\n",
    "side_angle = [ -0.3 ,  0. ,  0.9,  0, 0, -0.7,  1.87, -1.07,  0.0]\n",
    "stand_up = [-0.15, 0., 0.34, 0.74, -1.34, -0., 1.1, -0.66, -0.1]\n",
    "\n",
    "lean_back = [-0.27, 0., -0.45, 0.22, -1.5, 0.86, 0.6, -0.8, -0.4]\n",
    "boat = [ -1.04 ,  0. ,  -0.8,  1.6, 0. , 0.0, 1.6, -0.,  0.0]\n",
    "bridge = [-1.1, 0., -2.2, -0.3, -1.5, 0., -0.3, -0.8, -0.4]\n",
    "\n",
    "head_stand = [-1, 0., -3, 0.6, -1, -0.3, 0.9, -0.5, 0.3]\n",
    "one_feet = [-0.2, 0., 0, 0.7, -1.34, 0.5, 1.5, -0.6, 0.1]\n",
    "arabesque = [-0.34, 0., 1.57, 1.57, 0, 0., 0, -0., 0.]\n",
    "\n",
    "down_with_leg_out = [-1.05549, -0.4248, -2.1923, -0.3573, -1.509, 0.017559  , -0.358, -0.41552893, -0.79436103]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c40192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.physics.data.qpos = kneel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78c39a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.physics.forward()\n",
    "phy_state = env.physics.get_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b5270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = Path(\"files/yoga\")\n",
    "folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef835530",
   "metadata": {},
   "outputs": [],
   "source": [
    "_img= env.physics.render(480, 640, 0)\n",
    "media.write_image(folder / \"goal.png\", _img)\n",
    "plt.imshow(_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87f5adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = list(env.task.get_observation(env.physics).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a54a532",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.concatenate([values[0], np.array([values[1]]), values[2]])\n",
    "# state = np.concatenate([values[0], np.array([values[1]])])\n",
    "goal_state = state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07f8ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_len = cfg.model_config.traj_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7ea4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "state[None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015bac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_states  = torch.from_numpy(state[None]).repeat(t_len, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5603f458",
   "metadata": {},
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f00bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MaskedDP(data_shapes, cfg.model_config)\n",
    "model.to(cfg.device)\n",
    "model.train()\n",
    "\n",
    "# load weights\n",
    "model.load_state_dict(torch.load(ckpt_path)[\"model\"])\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1082725",
   "metadata": {},
   "outputs": [],
   "source": [
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309a4853",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230568bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_torch = {\n",
    "    \"states\": torch_states.to(cfg.device, torch.float32).unsqueeze(0),\n",
    "    \"actions\": torch.from_numpy(sample_trajectory_with_metadata[\"actions\"])\n",
    "    .to(cfg.device)\n",
    "    .unsqueeze(0),\n",
    "}\n",
    "\n",
    "\n",
    "# goalreaching mask\n",
    "prediction_steps = t_len - 1\n",
    "state_mask = torch.ones(batch_torch[\"states\"].shape[1])\n",
    "action_mask = torch.zeros(batch_torch[\"actions\"].shape[1])\n",
    "masks = {\"states\": state_mask, \"actions\": action_mask}\n",
    "masks_torch = {k: v.to(cfg.device) for k, v in masks.items()}\n",
    "\n",
    "\n",
    "# #shorten everything to the prediction_steps\n",
    "# for k in masks.keys():\n",
    "#     masks_torch[k] = masks_torch[k][:prediction_steps+1]\n",
    "#     batch_torch[k] = batch_torch[k][:prediction_steps+1]\n",
    "\n",
    "encoded_batch = tokenizer_manager.encode(batch_torch)\n",
    "predicted_trajectories = model(encoded_batch, masks_torch)\n",
    "decoded_trajectories = tokenizer_manager.decode(predicted_trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bca8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c9df3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_actions():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba55caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "with env.physics.reset_context():\n",
    "    env.physics.set_state(phy_state)\n",
    "    \n",
    "images_open_loop = [env.physics.render(480, 640, 0)]\n",
    "execute_actions = decoded_trajectories[\"actions\"].squeeze(0).detach().cpu().numpy()\n",
    "traj_real_ol = defaultdict(list)\n",
    "traj_real_ol[\"states\"].append(goal_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1611fecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "with env.physics.reset_context():\n",
    "    env.physics.set_state(phy_state)\n",
    "    \n",
    "images_open_loop = [env.physics.render(480, 640, 0)]\n",
    "execute_actions = decoded_trajectories[\"actions\"].squeeze(0).detach().cpu().numpy()\n",
    "traj_real_ol = defaultdict(list)\n",
    "traj_real_ol[\"states\"].append(goal_state)\n",
    "\n",
    "for idx, action in enumerate(execute_actions):\n",
    "    traj_real_ol[\"actions\"].append(action)\n",
    "    obs = env.step(action)[0]\n",
    "    traj_real_ol[\"states\"].append(obs)\n",
    "    image = env.physics.render(480, 640, 0)\n",
    "    images_open_loop.append(image)\n",
    "    \n",
    "traj_real_ol[\"states\"] = traj_real_ol[\"states\"][:-1]\n",
    "    # compare obs against data\n",
    "#     _obs = sample_trajectory_with_metadata[\"observations\"]\n",
    "#     np.testing.assert_allclose(obs, _obs[idx], atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb395e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf = np.array(images_open_loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b54954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40da4c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "media.show_video(images_open_loop, fps=30)\n",
    "media.write_video(folder / \"open_loop.gif\", np.array(images_open_loop), codec='gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cc4731",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_n_plots = 3\n",
    "for k, _ in decoded_trajectories.items():\n",
    "    traj = batch_torch[k][0].detach().cpu().numpy()\n",
    "    pred_traj = decoded_trajectories[k][0].detach().cpu().numpy()\n",
    "    mask = masks[k]\n",
    "    for i in range(min(max_n_plots, traj.shape[-1])):\n",
    "        gt_i = traj[:, i]\n",
    "        re_i = pred_traj[:, i]\n",
    "        real_i = np.array(traj_real_ol[k])[:, i]\n",
    "        if len(mask.shape) == 1:\n",
    "            # only along time dimension: repeat across the given dimension\n",
    "            mask = mask[:, None].repeat(1, traj.shape[1])\n",
    "        select_mask = mask[:, i].cpu().numpy()\n",
    "        unmasked_gt_i = gt_i[select_mask == 1]\n",
    "        unmasked_gt_i_index = np.arange(len(gt_i))[select_mask == 1]\n",
    "        vmax = max(np.max(gt_i), np.max(re_i), np.max(real_i))\n",
    "        vmin = min(np.min(gt_i), np.min(re_i), np.min(real_i))\n",
    "        y_range = vmax - vmin\n",
    "        with ph.plot_context() as (fig, ax):\n",
    "\n",
    "            ax.plot(gt_i, \"-o\", label=\"ground truth\")\n",
    "            ax.plot(\n",
    "                re_i, \"-o\", label=\"reconstructed\", markerfacecolor=\"none\"\n",
    "            )\n",
    "            ax.plot(\n",
    "                unmasked_gt_i_index,\n",
    "                unmasked_gt_i,\n",
    "                \"o\",\n",
    "                label=\"unmasked ground truth\",\n",
    "            )\n",
    "            ax.plot(\n",
    "                real_i, \".\", label=\"real\"\n",
    "            )\n",
    "            ax.set_ylim(\n",
    "                vmin - y_range / 5,\n",
    "                vmax + y_range / 5,\n",
    "            )\n",
    "            ax.legend()\n",
    "            ax.set_title(f\"{k}_{i}\")\n",
    "            plt.show()\n",
    "#             eval_logs[\n",
    "#                 f\"{eval_name}/batch={batch_idx}|{i}_{k}\"\n",
    "#             ] = wandb.Image(ph.plot_as_image(fig))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2321cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run closed loop\n",
    "batch_torch = {\n",
    "    \"states\": torch_states.to(cfg.device, torch.float32).unsqueeze(0),\n",
    "    \"actions\": torch.from_numpy(sample_trajectory_with_metadata[\"actions\"])\n",
    "    .to(cfg.device)\n",
    "    .unsqueeze(0),\n",
    "}\n",
    "\n",
    "\n",
    "# goalreaching mask\n",
    "state_mask = torch.ones(batch_torch[\"states\"].shape[1])\n",
    "action_mask = torch.zeros(batch_torch[\"actions\"].shape[1])\n",
    "masks = {\"states\": state_mask, \"actions\": action_mask}\n",
    "masks_torch = {k: v.to(cfg.device) for k, v in masks.items()}\n",
    "\n",
    "# #shorten everything to the prediction_steps\n",
    "# for k in masks.keys():\n",
    "#     masks_torch[k] = masks_torch[k][:prediction_steps+1]\n",
    "#     batch_torch[k] = batch_torch[k][:prediction_steps+1]\n",
    "\n",
    "env.reset()\n",
    "with env.physics.reset_context():\n",
    "    env.physics.set_state(phy_state)\n",
    "\n",
    "images_close_loop = [env.physics.render(480, 640, 0)]\n",
    "traj_real_cl = defaultdict(list)\n",
    "traj_real_cl[\"states\"].append(goal_state)\n",
    "\n",
    "\n",
    "for i in range(prediction_steps):\n",
    "    encoded_batch = tokenizer_manager.encode(batch_torch)\n",
    "    predicted_trajectories = model(encoded_batch, masks_torch)\n",
    "    decoded_trajectories = tokenizer_manager.decode(predicted_trajectories)\n",
    "    \n",
    "    a = decoded_trajectories[\"actions\"][0][i].detach().cpu().numpy()\n",
    "    batch_torch[\"actions\"][0][i] = torch.tensor(a, device=\"cuda\")\n",
    "    traj_real_cl[\"actions\"].append(a)\n",
    "    obs = env.step(a)[0]\n",
    "    traj_real_cl[\"states\"].append(obs)\n",
    "    image = env.physics.render(480, 640, 0)\n",
    "    images_close_loop.append(image)\n",
    "    masks[\"states\"][i] = 1\n",
    "    masks[\"actions\"][i] = 1\n",
    "    masks_torch = {k: v.to(cfg.device) for k, v in masks.items()}\n",
    "    batch_torch[\"states\"][0][i + 1] = torch.tensor(obs, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d44e3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "media.show_video(images_close_loop, fps=30)\n",
    "media.write_video(folder / \"close_loop.gif\", images_close_loop, fps=30, codec='gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64531e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(traj_real_cl[k])[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c7680a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_n_plots = 3\n",
    "for k, _ in decoded_trajectories.items():\n",
    "    traj = torch_states.numpy()\n",
    "    pred_traj = decoded_trajectories[k][0].detach().cpu().numpy()\n",
    "    mask = masks[k]\n",
    "    for i in range(min(max_n_plots, traj.shape[-1])):\n",
    "        gt_i = traj[:, i]\n",
    "        re_i = pred_traj[:, i]\n",
    "        real_i = np.array(traj_real_cl[k])[:, i]\n",
    "        if len(mask.shape) == 1:\n",
    "            # only along time dimension: repeat across the given dimension\n",
    "            mask = mask[:, None].repeat(1, traj.shape[1])\n",
    "        select_mask = mask[:, i].cpu().numpy()\n",
    "        unmasked_gt_i = gt_i[select_mask == 1]\n",
    "        unmasked_gt_i_index = np.arange(len(gt_i))[select_mask == 1]\n",
    "        vmax = max(np.max(gt_i), np.max(re_i))\n",
    "        vmin = min(np.min(gt_i), np.min(re_i))\n",
    "        y_range = vmax - vmin\n",
    "        with ph.plot_context() as (fig, ax):\n",
    "\n",
    "            ax.plot(gt_i, \"-o\", label=\"ground truth\")\n",
    "            ax.plot(\n",
    "                re_i, \"-o\", label=\"reconstructed\", markerfacecolor=\"none\"\n",
    "            )\n",
    "            ax.plot(\n",
    "                unmasked_gt_i_index,\n",
    "                unmasked_gt_i,\n",
    "                \"o\",\n",
    "                label=\"unmasked ground truth\",\n",
    "            )\n",
    "            ax.plot(\n",
    "                real_i, \".\", label=\"real\"\n",
    "            )\n",
    "            ax.set_ylim(\n",
    "                vmin - y_range / 5,\n",
    "                vmax + y_range / 5,\n",
    "            )\n",
    "            ax.legend()\n",
    "            ax.set_title(f\"{k}_{i}\")\n",
    "            plt.show()\n",
    "#             eval_logs[\n",
    "#                 f\"{eval_name}/batch={batch_idx}|{i}_{k}\"\n",
    "#             ] = wandb.Image(ph.plot_as_image(fig))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02232f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_cl = goal_state - traj_real_cl[\"states\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdec6e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2049c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(diff_cl**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218fbaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_ol = goal_state - traj_real_ol[\"states\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff5b18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(diff_ol**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4813eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_real_cl[\"states\"][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a9f2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run closed loop\n",
    "batch_torch = {\n",
    "    \"states\": torch_states.to(cfg.device, torch.float32).unsqueeze(0),\n",
    "    \"actions\": torch.from_numpy(sample_trajectory_with_metadata[\"actions\"])\n",
    "    .to(cfg.device)\n",
    "    .unsqueeze(0),\n",
    "}\n",
    "\n",
    "\n",
    "# goalreaching mask\n",
    "state_mask = torch.zeros(batch_torch[\"states\"].shape[1])\n",
    "state_mask[:3] = 1\n",
    "state_mask[-3:] = 1\n",
    "action_mask = torch.zeros(batch_torch[\"actions\"].shape[1])\n",
    "masks = {\"states\": state_mask, \"actions\": action_mask}\n",
    "masks_torch = {k: v.to(cfg.device) for k, v in masks.items()}\n",
    "\n",
    "# #shorten everything to the prediction_steps\n",
    "# for k in masks.keys():\n",
    "#     masks_torch[k] = masks_torch[k][:prediction_steps+1]\n",
    "#     batch_torch[k] = batch_torch[k][:prediction_steps+1]\n",
    "\n",
    "env.reset()\n",
    "with env.physics.reset_context():\n",
    "    env.physics.set_state(phy_state)\n",
    "\n",
    "images_close_loop = [env.physics.render(480, 640, 0)]\n",
    "traj_real_cl = defaultdict(list)\n",
    "traj_real_cl[\"states\"].append(sample_trajectory_with_metadata[\"observations\"][0])\n",
    "\n",
    "    \n",
    "\n",
    "for i in range(prediction_steps):\n",
    "    encoded_batch = tokenizer_manager.encode(batch_torch)\n",
    "    predicted_trajectories = model(encoded_batch, masks_torch)\n",
    "    decoded_trajectories = tokenizer_manager.decode(predicted_trajectories)\n",
    "    \n",
    "    a = decoded_trajectories[\"actions\"][0][i].detach().cpu().numpy()\n",
    "    batch_torch[\"actions\"][0][i] = torch.tensor(a, device=\"cuda\")\n",
    "    traj_real_cl[\"actions\"].append(a)\n",
    "    time_step = env.step(a)[0]\n",
    "    traj_real_cl[\"states\"].append(time_step)\n",
    "    image = env.physics.render(480, 640, 0)\n",
    "    images_close_loop.append(image)\n",
    "    masks[\"states\"][i] = 1\n",
    "    masks[\"actions\"][i] = 1\n",
    "    masks_torch = {k: v.to(cfg.device) for k, v in masks.items()}\n",
    "    batch_torch[\"states\"][0][i + 1] = torch.tensor(time_step, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef43500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "media.show_video(images_close_loop, fps=30)\n",
    "media.write_video(folder / \"close_loop_goal.gif\", images_close_loop, fps=30, codec='gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77c602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n_plots = 3\n",
    "for k, _ in decoded_trajectories.items():\n",
    "    traj = torch_states.numpy()\n",
    "    pred_traj = decoded_trajectories[k][0].detach().cpu().numpy()\n",
    "    mask = masks[k]\n",
    "    for i in range(min(max_n_plots, traj.shape[-1])):\n",
    "        gt_i = traj[:, i]\n",
    "        re_i = pred_traj[:, i]\n",
    "        real_i = np.array(traj_real_cl[k])[:, i]\n",
    "        if len(mask.shape) == 1:\n",
    "            # only along time dimension: repeat across the given dimension\n",
    "            mask = mask[:, None].repeat(1, traj.shape[1])\n",
    "        select_mask = mask[:, i].cpu().numpy()\n",
    "        unmasked_gt_i = gt_i[select_mask == 1]\n",
    "        unmasked_gt_i_index = np.arange(len(gt_i))[select_mask == 1]\n",
    "        vmax = max(np.max(gt_i), np.max(re_i))\n",
    "        vmin = min(np.min(gt_i), np.min(re_i))\n",
    "        y_range = vmax - vmin\n",
    "        with ph.plot_context() as (fig, ax):\n",
    "\n",
    "            ax.plot(gt_i, \"-o\", label=\"ground truth\")\n",
    "            ax.plot(\n",
    "                re_i, \"-o\", label=\"reconstructed\", markerfacecolor=\"none\"\n",
    "            )\n",
    "            ax.plot(\n",
    "                unmasked_gt_i_index,\n",
    "                unmasked_gt_i,\n",
    "                \"o\",\n",
    "                label=\"unmasked ground truth\",\n",
    "            )\n",
    "            ax.plot(\n",
    "                real_i, \".\", label=\"real\"\n",
    "            )\n",
    "            ax.set_ylim(\n",
    "                vmin - y_range / 5,\n",
    "                vmax + y_range / 5,\n",
    "            )\n",
    "            ax.legend()\n",
    "            ax.set_title(f\"{k}_{i}\")\n",
    "            plt.show()\n",
    "#             eval_logs[\n",
    "#                 f\"{eval_name}/batch={batch_idx}|{i}_{k}\"\n",
    "#             ] = wandb.Image(ph.plot_as_image(fig))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b591895d",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_cl = goal_state - traj_real_cl[\"states\"][-1]\n",
    "np.sum(diff_cl**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccd1d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22dfb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_reach_states = torch_states.clone()\n",
    "loc = 0\n",
    "goal_reach_states[:3] = torch.tensor(sample_trajectory_with_metadata[\"observations\"][loc:loc+3, :])\n",
    "physics_start = sample_trajectory_with_metadata[\"physics\"][loc]\n",
    "alpha = torch.linspace(0, 1, t_len)\n",
    "goal_reach_states = goal_reach_states[0] + (goal_reach_states[-1] - goal_reach_states[0]) * alpha[:, None]\n",
    "\n",
    "\n",
    "# run closed loop\n",
    "batch_torch = {\n",
    "    \"states\": goal_reach_states.to(cfg.device, torch.float32).unsqueeze(0),\n",
    "    \"actions\": torch.from_numpy(sample_trajectory_with_metadata[\"actions\"])\n",
    "    .to(cfg.device)\n",
    "    .unsqueeze(0),\n",
    "}\n",
    "\n",
    "\n",
    "# goalreaching mask\n",
    "state_mask = torch.zeros(batch_torch[\"states\"].shape[1])\n",
    "state_mask[:3] = 1\n",
    "state_mask[-3:] = 1\n",
    "action_mask = torch.zeros(batch_torch[\"actions\"].shape[1])\n",
    "masks = {\"states\": state_mask, \"actions\": action_mask}\n",
    "masks_torch = {k: v.to(cfg.device) for k, v in masks.items()}\n",
    "\n",
    "encoded_batch = tokenizer_manager.encode(batch_torch)\n",
    "predicted_trajectories = model(encoded_batch, masks_torch)\n",
    "decoded_trajectories = tokenizer_manager.decode(predicted_trajectories)\n",
    "\n",
    "env.reset()\n",
    "with env.physics.reset_context():\n",
    "    env.physics.set_state(physics_start)\n",
    "\n",
    "images_close_loop = [env.physics.render(480, 640, 0)]\n",
    "execute_actions = decoded_trajectories[\"actions\"].squeeze(0).detach().cpu().numpy()\n",
    "traj_real_cl = defaultdict(list)\n",
    "traj_real_cl[\"states\"].append(sample_trajectory_with_metadata[\"observations\"][0])\n",
    "\n",
    "\n",
    "\n",
    "for idx, action in enumerate(execute_actions):\n",
    "    traj_real_cl[\"actions\"].append(action)\n",
    "    obs = env.step(action)[0]\n",
    "    traj_real_cl[\"states\"].append(obs)\n",
    "    image = env.physics.render(480, 640, 0)\n",
    "    images_close_loop.append(image)\n",
    "    \n",
    "traj_real_cl[\"states\"] = traj_real_cl[\"states\"][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e798e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a21b66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "media.show_video(images_close_loop, fps=30)\n",
    "media.write_video(folder / \"open_loop_reach_from_random.gif\", images_close_loop, fps=30, codec='gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7606cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_n_plots = 3\n",
    "for k, _ in decoded_trajectories.items():\n",
    "    traj = goal_reach_states.numpy()\n",
    "    pred_traj = decoded_trajectories[k][0].detach().cpu().numpy()\n",
    "    mask = masks[k]\n",
    "    for i in range(min(max_n_plots, traj.shape[-1])):\n",
    "        gt_i = traj[:, i]\n",
    "        re_i = pred_traj[:, i]\n",
    "        real_i = np.array(traj_real_cl[k])[:, i]\n",
    "        if len(mask.shape) == 1:\n",
    "            # only along time dimension: repeat across the given dimension\n",
    "            mask = mask[:, None].repeat(1, traj.shape[1])\n",
    "        select_mask = mask[:, i].cpu().numpy()\n",
    "        unmasked_gt_i = gt_i[select_mask == 1]\n",
    "        unmasked_gt_i_index = np.arange(len(gt_i))[select_mask == 1]\n",
    "        vmax = max(np.max(gt_i), np.max(re_i))\n",
    "        vmin = min(np.min(gt_i), np.min(re_i))\n",
    "        y_range = vmax - vmin\n",
    "        with ph.plot_context() as (fig, ax):\n",
    "\n",
    "            ax.plot(gt_i, \"-o\", label=\"ground truth\")\n",
    "            ax.plot(\n",
    "                re_i, \"-o\", label=\"reconstructed\", markerfacecolor=\"none\"\n",
    "            )\n",
    "            ax.plot(\n",
    "                unmasked_gt_i_index,\n",
    "                unmasked_gt_i,\n",
    "                \"o\",\n",
    "                label=\"unmasked ground truth\",\n",
    "            )\n",
    "            ax.plot(\n",
    "                real_i, \".\", label=\"real\"\n",
    "            )\n",
    "            ax.set_ylim(\n",
    "                vmin - y_range / 5,\n",
    "                vmax + y_range / 5,\n",
    "            )\n",
    "            ax.legend()\n",
    "            ax.set_title(f\"{k}_{i}\")\n",
    "            plt.show()\n",
    "#             eval_logs[\n",
    "#                 f\"{eval_name}/batch={batch_idx}|{i}_{k}\"\n",
    "#             ] = wandb.Image(ph.plot_as_image(fig))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fe7973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e741117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_reach_states = torch_states.clone()\n",
    "loc = 0\n",
    "goal_reach_states[:3] = torch.tensor(sample_trajectory_with_metadata[\"observations\"][loc:loc+3, :])\n",
    "physics_start = sample_trajectory_with_metadata[\"physics\"][loc]\n",
    "alpha = torch.linspace(0, 1, t_len)\n",
    "goal_reach_states = goal_reach_states[0] + (goal_reach_states[-1] - goal_reach_states[0]) * alpha[:, None]\n",
    "\n",
    "\n",
    "# run closed loop\n",
    "batch_torch = {\n",
    "    \"states\": goal_reach_states.to(cfg.device, torch.float32).unsqueeze(0),\n",
    "    \"actions\": torch.from_numpy(sample_trajectory_with_metadata[\"actions\"])\n",
    "    .to(cfg.device)\n",
    "    .unsqueeze(0),\n",
    "}\n",
    "\n",
    "\n",
    "# goalreaching mask\n",
    "state_mask = torch.zeros(batch_torch[\"states\"].shape[1])\n",
    "state_mask[:3] = 1\n",
    "state_mask[-3:] = 1\n",
    "action_mask = torch.zeros(batch_torch[\"actions\"].shape[1])\n",
    "masks = {\"states\": state_mask, \"actions\": action_mask}\n",
    "masks_torch = {k: v.to(cfg.device) for k, v in masks.items()}\n",
    "\n",
    "encoded_batch = tokenizer_manager.encode(batch_torch)\n",
    "predicted_trajectories = model(encoded_batch, masks_torch)\n",
    "decoded_trajectories = tokenizer_manager.decode(predicted_trajectories)\n",
    "\n",
    "env.reset()\n",
    "with env.physics.reset_context():\n",
    "    env.physics.set_state(physics_start)\n",
    "\n",
    "images_close_loop = [env.physics.render(480, 640, 0)]\n",
    "traj_real_cl = defaultdict(list)\n",
    "traj_real_cl[\"states\"].append(sample_trajectory_with_metadata[\"observations\"][0][:])\n",
    "\n",
    "for i in range(prediction_steps):\n",
    "    encoded_batch = tokenizer_manager.encode(batch_torch)\n",
    "    predicted_trajectories = model(encoded_batch, masks_torch)\n",
    "    decoded_trajectories = tokenizer_manager.decode(predicted_trajectories)\n",
    "    \n",
    "    a = decoded_trajectories[\"actions\"][0][i].detach().cpu().numpy()\n",
    "    batch_torch[\"actions\"][0][i] = torch.tensor(a, device=\"cuda\")\n",
    "    traj_real_cl[\"actions\"].append(a)\n",
    "    time_step = env.step(a)[0]\n",
    "    traj_real_cl[\"states\"].append(time_step)\n",
    "    image = env.physics.render(480, 640, 0)\n",
    "    images_close_loop.append(image)\n",
    "    masks[\"states\"][i] = 1\n",
    "    masks[\"actions\"][i] = 1\n",
    "    masks_torch = {k: v.to(cfg.device) for k, v in masks.items()}\n",
    "    batch_torch[\"states\"][0][i + 1] = torch.tensor(time_step, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8c8887",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_n_plots = 3\n",
    "for k, _ in decoded_trajectories.items():\n",
    "    traj = goal_reach_states.numpy()\n",
    "    pred_traj = decoded_trajectories[k][0].detach().cpu().numpy()\n",
    "    mask = masks[k]\n",
    "    for i in range(min(max_n_plots, traj.shape[-1])):\n",
    "        gt_i = traj[:, i]\n",
    "        re_i = pred_traj[:, i]\n",
    "        real_i = np.array(traj_real_cl[k])[:, i]\n",
    "        if len(mask.shape) == 1:\n",
    "            # only along time dimension: repeat across the given dimension\n",
    "            mask = mask[:, None].repeat(1, traj.shape[1])\n",
    "        select_mask = mask[:, i].cpu().numpy()\n",
    "        unmasked_gt_i = gt_i[select_mask == 1]\n",
    "        unmasked_gt_i_index = np.arange(len(gt_i))[select_mask == 1]\n",
    "        vmax = max(np.max(gt_i), np.max(re_i))\n",
    "        vmin = min(np.min(gt_i), np.min(re_i))\n",
    "        y_range = vmax - vmin\n",
    "        with ph.plot_context() as (fig, ax):\n",
    "\n",
    "            ax.plot(gt_i, \"-o\", label=\"ground truth\")\n",
    "            ax.plot(\n",
    "                re_i, \"-o\", label=\"reconstructed\", markerfacecolor=\"none\"\n",
    "            )\n",
    "            ax.plot(\n",
    "                unmasked_gt_i_index,\n",
    "                unmasked_gt_i,\n",
    "                \"o\",\n",
    "                label=\"unmasked ground truth\",\n",
    "            )\n",
    "            ax.plot(\n",
    "                real_i, \".\", label=\"real\"\n",
    "            )\n",
    "            ax.set_ylim(\n",
    "                vmin - y_range / 5,\n",
    "                vmax + y_range / 5,\n",
    "            )\n",
    "            ax.legend()\n",
    "            ax.set_title(f\"{k}_{i}\")\n",
    "            plt.show()\n",
    "#             eval_logs[\n",
    "#                 f\"{eval_name}/batch={batch_idx}|{i}_{k}\"\n",
    "#             ] = wandb.Image(ph.plot_as_image(fig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76058d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "media.show_video(images_close_loop, fps=30)\n",
    "media.write_video(folder / \"closed_loop_reach_from_random.gif\", images_close_loop, fps=30, codec='gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11743f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585d02f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea784648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbdfdb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6250a204",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_trajectory_with_metadata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca31c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_torch = {\n",
    "    \"states\": torch.from_numpy(sample_trajectory_with_metadata[\"observations\"])\n",
    "    .to(cfg.device)\n",
    "    .unsqueeze(0),\n",
    "    \"actions\": torch.from_numpy(sample_trajectory_with_metadata[\"actions\"])\n",
    "    .to(cfg.device)\n",
    "    .unsqueeze(0),\n",
    "}\n",
    "\n",
    "\n",
    "# goalreaching mask\n",
    "state_mask = torch.zeros(batch_torch[\"states\"].shape[1])\n",
    "state_mask[0:3] = 1\n",
    "state_mask[-3:] = 1\n",
    "action_mask = torch.zeros(batch_torch[\"actions\"].shape[1])\n",
    "masks = {\"states\": state_mask, \"actions\": action_mask}\n",
    "masks_torch = {k: v.to(cfg.device) for k, v in masks.items()}\n",
    "\n",
    "encoded_batch = tokenizer_manager.encode(batch_torch)\n",
    "predicted_trajectories = model(encoded_batch, masks_torch)\n",
    "decoded_trajectories = tokenizer_manager.decode(predicted_trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894a3bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.physics.reset()\n",
    "with env.physics.reset_context():\n",
    "    env.physics.set_state(sample_trajectory_with_metadata[\"physics\"][0])\n",
    "    \n",
    "images_open_loop = [env.physics.render(480, 640, 0)]\n",
    "execute_actions = decoded_trajectories[\"actions\"].squeeze(0).detach().cpu().numpy()\n",
    "traj_real_ol = defaultdict(list)\n",
    "traj_real_ol[\"states\"].append(sample_trajectory_with_metadata[\"observations\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c698b6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, action in enumerate(execute_actions):\n",
    "    traj_real_ol[\"actions\"].append(action)\n",
    "    obs = env.step(action)[0]\n",
    "    traj_real_ol[\"states\"].append(obs)\n",
    "    image = env.physics.render(480, 640, 0)\n",
    "    images_open_loop.append(image)\n",
    "    \n",
    "traj_real_ol[\"states\"] = traj_real_ol[\"states\"][:-1]\n",
    "    # compare obs against data\n",
    "#     _obs = sample_trajectory_with_metadata[\"observations\"]\n",
    "#     np.testing.assert_allclose(obs, _obs[idx], atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0bb401",
   "metadata": {},
   "outputs": [],
   "source": [
    "media.show_video(images_open_loop, fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a73c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_n_plots = 3\n",
    "for k, _ in decoded_trajectories.items():\n",
    "    traj = batch_torch[k][0].detach().cpu().numpy()\n",
    "    pred_traj = decoded_trajectories[k][0].detach().cpu().numpy()\n",
    "    mask = masks[k]\n",
    "    for i in range(min(max_n_plots, traj.shape[-1])):\n",
    "        gt_i = traj[:, i]\n",
    "        re_i = pred_traj[:, i]\n",
    "        real_i = np.array(traj_real_ol[k])[:, i]\n",
    "        if len(mask.shape) == 1:\n",
    "            # only along time dimension: repeat across the given dimension\n",
    "            mask = mask[:, None].repeat(1, traj.shape[1])\n",
    "        select_mask = mask[:, i].cpu().numpy()\n",
    "        unmasked_gt_i = gt_i[select_mask == 1]\n",
    "        unmasked_gt_i_index = np.arange(len(gt_i))[select_mask == 1]\n",
    "        vmax = max(np.max(gt_i), np.max(re_i), np.max(real_i))\n",
    "        vmin = min(np.min(gt_i), np.min(re_i), np.min(real_i))\n",
    "        y_range = vmax - vmin\n",
    "        with ph.plot_context() as (fig, ax):\n",
    "\n",
    "            ax.plot(gt_i, \"-o\", label=\"ground truth\")\n",
    "            ax.plot(\n",
    "                re_i, \"-o\", label=\"reconstructed\", markerfacecolor=\"none\"\n",
    "            )\n",
    "            ax.plot(\n",
    "                unmasked_gt_i_index,\n",
    "                unmasked_gt_i,\n",
    "                \"o\",\n",
    "                label=\"unmasked ground truth\",\n",
    "            )\n",
    "            ax.plot(\n",
    "                real_i, \".\", label=\"real\"\n",
    "            )\n",
    "            ax.set_ylim(\n",
    "                vmin - y_range / 5,\n",
    "                vmax + y_range / 5,\n",
    "            )\n",
    "            ax.legend()\n",
    "            ax.set_title(f\"{k}_{i}\")\n",
    "            plt.show()\n",
    "#             eval_logs[\n",
    "#                 f\"{eval_name}/batch={batch_idx}|{i}_{k}\"\n",
    "#             ] = wandb.Image(ph.plot_as_image(fig))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eb0cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_real_ol[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88fafb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec54dad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30201a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c881ad9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779afd56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02687f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a17f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_dataset._episodes.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78b9e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "poses = []\n",
    "for i in range(1, 8+1):\n",
    "    p_=f'/checkpoint/aravraj/mtm_data/dmc_pose_dataset_dec7/dmc_walker_pose{i}-v1.pickle0'\n",
    "    poses.append(p_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845db6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fd29d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in poses:\n",
    "#     train_dataset._episodes[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea549206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset._episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972472a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # failure cases: 2, 3, 4, 5, \n",
    "# # works 0, 1, 6, 7\n",
    "\n",
    "# for i in range(8):\n",
    "#     episode = train_dataset._episodes[poses[i]]\n",
    "\n",
    "#     tl = train_dataset._traj_length\n",
    "#     # tl = 64\n",
    "\n",
    "#     idx=0\n",
    "\n",
    "#     obs = episode[\"observations\"][idx : idx + tl]\n",
    "#     action = episode[\"actions\"][idx : idx + tl]\n",
    "#     reward = episode[\"rewards\"][idx : idx + tl]\n",
    "#     timestep = np.arange(idx, idx + tl)[:, np.newaxis]\n",
    "#     physics = episode[\"states\"][idx: idx + tl]\n",
    "#     physics_ = [p[\"internal_state\"] for p in physics]\n",
    "#     sample_trajectory_with_metadata = {\n",
    "#         \"observations\": obs.astype(np.float32),\n",
    "#         \"actions\": action.astype(np.float32),\n",
    "#         \"rewards\": reward.astype(np.float32).reshape(-1, 1),\n",
    "#         \"timestep\": 0,\n",
    "#         \"physics\": physics_,\n",
    "#     }\n",
    "\n",
    "#     env.reset()\n",
    "#     with env.physics.reset_context():\n",
    "#         env.physics.set_state(sample_trajectory_with_metadata[\"physics\"][0])\n",
    "\n",
    "#     vis = [env.physics.render(480, 640, 0)]\n",
    "\n",
    "#     for idx, action in enumerate(sample_trajectory_with_metadata[\"actions\"]):\n",
    "#         env.step(action)\n",
    "#         image = env.physics.render(480, 640, 0)\n",
    "#         vis.append(image)\n",
    "\n",
    "#     #media.show_video(vis, fps=10)\n",
    "#     media.write_video(f\"gt_{i}.gif\", vis, fps=30, codec='gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d77cc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not working, 4, 5\n",
    "episode = train_dataset._episodes[poses[7]]\n",
    "\n",
    "tl = train_dataset._traj_length\n",
    "\n",
    "idx=0\n",
    "\n",
    "obs = episode[\"observations\"][idx : idx + tl]\n",
    "action = episode[\"actions\"][idx : idx + tl]\n",
    "reward = episode[\"rewards\"][idx : idx + tl]\n",
    "timestep = np.arange(idx, idx + tl)[:, np.newaxis]\n",
    "physics = episode[\"states\"][idx: idx + tl]\n",
    "physics_ = [p[\"internal_state\"] for p in physics]\n",
    "sample_trajectory_with_metadata = {\n",
    "    \"observations\": obs.astype(np.float32),\n",
    "    \"actions\": action.astype(np.float32),\n",
    "    \"rewards\": reward.astype(np.float32).reshape(-1, 1),\n",
    "    \"timestep\": 0,\n",
    "    \"physics\": physics_,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559b16a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.reset()\n",
    "\n",
    "# vis = []\n",
    "# for p in sample_trajectory_with_metadata[\"physics\"]:\n",
    "#     with env.physics.reset_context():\n",
    "#         env.physics.set_state(p)\n",
    "#     vis.append(env.physics.render(480, 640, 0))\n",
    "    \n",
    "# media.show_video(vis, fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bb3617",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "with env.physics.reset_context():\n",
    "    env.physics.set_state(sample_trajectory_with_metadata[\"physics\"][0])\n",
    "    \n",
    "vis = [env.physics.render(480, 640, 0)]\n",
    "\n",
    "for idx, action in enumerate(sample_trajectory_with_metadata[\"actions\"]):\n",
    "    env.step(action)\n",
    "    image = env.physics.render(480, 640, 0)\n",
    "    vis.append(image)\n",
    "    \n",
    "media.show_video(vis, fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eaedae",
   "metadata": {},
   "outputs": [],
   "source": [
    "hydra_cfg.tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0350e51b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafe9597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import copy\n",
    "# # tokenizer_info = hydra_cfg.tokenizers\n",
    "# # tokenizer_info = copy.copy(tokenizer_info)\n",
    "# # tokenizer_info[\"actions\"].num_bins = 64\n",
    "# hydra_cfg.tokenizers\n",
    "\n",
    "# tokenizers_: Dict[str, Tokenizer] = {\n",
    "#     k: hydra.utils.call(v, key=k, train_dataset=train_dataset)\n",
    "#     for k, v in tokenizer_info.items()\n",
    "# }\n",
    "# tm = TokenizerManager(tokenizers_)\n",
    "\n",
    "# env.reset()\n",
    "# with env.physics.reset_context():\n",
    "#     env.physics.set_state(sample_trajectory_with_metadata[\"physics\"][0])\n",
    "    \n",
    "# batch_torch = {\n",
    "#     \"states\": torch.from_numpy(sample_trajectory_with_metadata[\"observations\"])\n",
    "#     .to(cfg.device)\n",
    "#     .unsqueeze(0),\n",
    "#     \"actions\": torch.from_numpy(sample_trajectory_with_metadata[\"actions\"])\n",
    "#     .to(cfg.device)\n",
    "#     .unsqueeze(0),\n",
    "# }\n",
    "\n",
    "# encoded_batch = tm.encode(batch_torch)\n",
    "# decoded_trajectories = tm.decode(encoded_batch)\n",
    "# act = decoded_trajectories[\"actions\"][0].detach().cpu().numpy()\n",
    "\n",
    "# vis = [env.physics.render(480, 640, 0)]\n",
    "# for idx, action in enumerate(act):\n",
    "#     env.step(action)\n",
    "#     image = env.physics.render(480, 640, 0)\n",
    "#     vis.append(image)\n",
    "    \n",
    "# media.show_video(vis, fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b7bd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(2, 3)\n",
    "# for r in range(2):\n",
    "#     for j in range(3):\n",
    "#         i = r * 3 + j\n",
    "#         axs[r, j].plot(act[:, i], \"o\", label=\"discrete\")\n",
    "#         axs[r, j].plot(sample_trajectory_with_metadata[\"actions\"][:, i], \".\", label=\"original\")\n",
    "# axs[r, j].legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464b0691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314fcb4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed713575",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_torch = {\n",
    "    \"states\": torch.from_numpy(sample_trajectory_with_metadata[\"observations\"])\n",
    "    .to(cfg.device)\n",
    "    .unsqueeze(0),\n",
    "    \"actions\": torch.from_numpy(sample_trajectory_with_metadata[\"actions\"])\n",
    "    .to(cfg.device)\n",
    "    .unsqueeze(0),\n",
    "}\n",
    "\n",
    "\n",
    "# goalreaching mask\n",
    "state_mask = torch.zeros(batch_torch[\"states\"].shape[1])\n",
    "state_mask[0:3] = 1\n",
    "state_mask[-3:] = 1\n",
    "action_mask = torch.zeros(batch_torch[\"actions\"].shape[1])\n",
    "masks = {\"states\": state_mask, \"actions\": action_mask}\n",
    "masks_torch = {k: v.to(cfg.device) for k, v in masks.items()}\n",
    "\n",
    "encoded_batch = tokenizer_manager.encode(batch_torch)\n",
    "predicted_trajectories = model(encoded_batch, masks_torch)\n",
    "decoded_trajectories = tokenizer_manager.decode(predicted_trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35269eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.physics.reset()\n",
    "with env.physics.reset_context():\n",
    "    env.physics.set_state(sample_trajectory_with_metadata[\"physics\"][0])\n",
    "    \n",
    "images_open_loop = [env.physics.render(480, 640, 0)]\n",
    "execute_actions = decoded_trajectories[\"actions\"].squeeze(0).detach().cpu().numpy()\n",
    "traj_real_ol = defaultdict(list)\n",
    "traj_real_ol[\"states\"].append(sample_trajectory_with_metadata[\"observations\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c75e3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, action in enumerate(execute_actions):\n",
    "    traj_real_ol[\"actions\"].append(action)\n",
    "    obs = env.step(action)[0]\n",
    "    traj_real_ol[\"states\"].append(obs)\n",
    "    image = env.physics.render(480, 640, 0)\n",
    "    images_open_loop.append(image)\n",
    "    \n",
    "traj_real_ol[\"states\"] = traj_real_ol[\"states\"][:-1]\n",
    "    # compare obs against data\n",
    "#     _obs = sample_trajectory_with_metadata[\"observations\"]\n",
    "#     np.testing.assert_allclose(obs, _obs[idx], atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985d3707",
   "metadata": {},
   "outputs": [],
   "source": [
    "media.show_video(images_open_loop, fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5737afb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_n_plots = 3\n",
    "for k, _ in decoded_trajectories.items():\n",
    "    traj = batch_torch[k][0].detach().cpu().numpy()\n",
    "    pred_traj = decoded_trajectories[k][0].detach().cpu().numpy()\n",
    "    mask = masks[k]\n",
    "    for i in range(min(max_n_plots, traj.shape[-1])):\n",
    "        gt_i = traj[:, i]\n",
    "        re_i = pred_traj[:, i]\n",
    "        real_i = np.array(traj_real_ol[k])[:, i]\n",
    "        if len(mask.shape) == 1:\n",
    "            # only along time dimension: repeat across the given dimension\n",
    "            mask = mask[:, None].repeat(1, traj.shape[1])\n",
    "        select_mask = mask[:, i].cpu().numpy()\n",
    "        unmasked_gt_i = gt_i[select_mask == 1]\n",
    "        unmasked_gt_i_index = np.arange(len(gt_i))[select_mask == 1]\n",
    "        vmax = max(np.max(gt_i), np.max(re_i), np.max(real_i))\n",
    "        vmin = min(np.min(gt_i), np.min(re_i), np.min(real_i))\n",
    "        y_range = vmax - vmin\n",
    "        with ph.plot_context() as (fig, ax):\n",
    "\n",
    "            ax.plot(gt_i, \"-o\", label=\"ground truth\")\n",
    "            ax.plot(\n",
    "                re_i, \"-o\", label=\"reconstructed\", markerfacecolor=\"none\"\n",
    "            )\n",
    "            ax.plot(\n",
    "                unmasked_gt_i_index,\n",
    "                unmasked_gt_i,\n",
    "                \"o\",\n",
    "                label=\"unmasked ground truth\",\n",
    "            )\n",
    "            ax.plot(\n",
    "                real_i, \".\", label=\"real\"\n",
    "            )\n",
    "            ax.set_ylim(\n",
    "                vmin - y_range / 5,\n",
    "                vmax + y_range / 5,\n",
    "            )\n",
    "            ax.legend()\n",
    "            ax.set_title(f\"{k}_{i}\")\n",
    "            plt.show()\n",
    "#             eval_logs[\n",
    "#                 f\"{eval_name}/batch={batch_idx}|{i}_{k}\"\n",
    "#             ] = wandb.Image(ph.plot_as_image(fig))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1604384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab1e050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# closed loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a83c0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_torch = {\n",
    "    \"states\": torch.from_numpy(sample_trajectory_with_metadata[\"observations\"])\n",
    "    .to(cfg.device)\n",
    "    .unsqueeze(0),\n",
    "    \"actions\": torch.from_numpy(sample_trajectory_with_metadata[\"actions\"])\n",
    "    .to(cfg.device)\n",
    "    .unsqueeze(0),\n",
    "}\n",
    "\n",
    "# goal reaching mask\n",
    "state_mask = torch.zeros(batch_torch[\"states\"].shape[1])\n",
    "state_mask[:3] = 1\n",
    "state_mask[-3:] = 1\n",
    "action_mask = torch.zeros(batch_torch[\"actions\"].shape[1])\n",
    "masks = {\"states\": state_mask, \"actions\": action_mask}\n",
    "masks_torch = {k: v.to(cfg.device) for k, v in masks.items()}\n",
    "\n",
    "encoded_batch = tokenizer_manager.encode(batch_torch)\n",
    "predicted_trajectories = model(encoded_batch, masks_torch)\n",
    "decoded_trajectories = tokenizer_manager.decode(predicted_trajectories)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1475c645",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.physics.reset()\n",
    "with env.physics.reset_context():\n",
    "    env.physics.set_state(sample_trajectory_with_metadata[\"physics\"][0])\n",
    "\n",
    "images_close_loop = [env.physics.render(480, 640, 0)]\n",
    "traj_real_cl = defaultdict(list)\n",
    "traj_real_cl[\"states\"].append(sample_trajectory_with_metadata[\"observations\"][0][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedcb1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(prediction_steps):\n",
    "    encoded_batch = tokenizer_manager.encode(batch_torch)\n",
    "    predicted_trajectories = model(encoded_batch, masks_torch)\n",
    "    decoded_trajectories = tokenizer_manager.decode(predicted_trajectories)\n",
    "    \n",
    "    a = decoded_trajectories[\"actions\"][0][i].detach().cpu().numpy()\n",
    "    batch_torch[\"actions\"][0][i] = torch.tensor(a, device=\"cuda\")\n",
    "    traj_real_cl[\"actions\"].append(a)\n",
    "    time_step = env.step(a)[0]\n",
    "    traj_real_cl[\"states\"].append(time_step)\n",
    "    image = env.physics.render(480, 640, 0)\n",
    "    images_close_loop.append(image)\n",
    "    masks[\"states\"][i+1] = 1\n",
    "    masks[\"actions\"][i] = 1\n",
    "    masks_torch = {k: v.to(cfg.device) for k, v in masks.items()}\n",
    "    batch_torch[\"states\"][0][i + 1] = torch.tensor(time_step, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7526a682",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c889f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "media.show_video(images_close_loop, fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c21c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "media.show_image(images_close_loop[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68de61f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n_plots = 3\n",
    "for k, _ in decoded_trajectories.items():\n",
    "    traj = goal_reach_states.numpy()\n",
    "    pred_traj = decoded_trajectories[k][0].detach().cpu().numpy()\n",
    "    mask = masks[k]\n",
    "    for i in range(min(max_n_plots, traj.shape[-1])):\n",
    "        gt_i = sample_trajectory_with_metadata[\"observations\"][:, i]\n",
    "        re_i = pred_traj[:, i]\n",
    "        real_i = np.array(traj_real_cl[k])[:, i]\n",
    "        if len(mask.shape) == 1:\n",
    "            # only along time dimension: repeat across the given dimension\n",
    "            mask = mask[:, None].repeat(1, traj.shape[1])\n",
    "        select_mask = mask[:, i].cpu().numpy()\n",
    "        unmasked_gt_i = gt_i[select_mask == 1]\n",
    "        unmasked_gt_i_index = np.arange(len(gt_i))[select_mask == 1]\n",
    "        vmax = max(np.max(gt_i), np.max(re_i))\n",
    "        vmin = min(np.min(gt_i), np.min(re_i))\n",
    "        y_range = vmax - vmin\n",
    "        with ph.plot_context() as (fig, ax):\n",
    "\n",
    "            ax.plot(gt_i, \"-o\", label=\"ground truth\")\n",
    "            ax.plot(\n",
    "                re_i, \"-o\", label=\"reconstructed\", markerfacecolor=\"none\"\n",
    "            )\n",
    "            ax.plot(\n",
    "                unmasked_gt_i_index,\n",
    "                unmasked_gt_i,\n",
    "                \"o\",\n",
    "                label=\"unmasked ground truth\",\n",
    "            )\n",
    "            ax.plot(\n",
    "                real_i, \".\", label=\"real\"\n",
    "            )\n",
    "            ax.set_ylim(\n",
    "                vmin - y_range / 5,\n",
    "                vmax + y_range / 5,\n",
    "            )\n",
    "            ax.legend()\n",
    "            ax.set_title(f\"{k}_{i}\")\n",
    "            plt.show()\n",
    "#             eval_logs[\n",
    "#                 f\"{eval_name}/batch={batch_idx}|{i}_{k}\"\n",
    "#             ] = wandb.Image(ph.plot_as_image(fig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658b4d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3f9ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48b3899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41963c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
