{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1ba950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MUJOCO_GL\"] = \"egl\"\n",
    "    \n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Callable, Dict, Tuple\n",
    "from pprint import pprint\n",
    "\n",
    "import dcargs\n",
    "import glob\n",
    "import hydra\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from research.logger import WandBLogger, WandBLoggerConfig\n",
    "from research.mtm.models.mtm_model import MaskedDP, MTMConfig, make_plots_with_masks\n",
    "from research.mtm.models.mlp_model import MLPConfig, MLP_BC\n",
    "from research.mtm.tokenizers.base import Tokenizer, TokenizerManager\n",
    "import mediapy as media\n",
    "from research.mtm.train_mlp import RunConfig\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from research.utils.plot_utils import PlotHandler as ph\n",
    "from pathlib import Path\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "from research.mtm.datasets.sequence_dataset import evaluate\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828000a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/private/home/philippwu/mtm/outputs/mtm_mae/2023-01-04_09-08-01/0_args.traj_length=2,dataset.env_name=walker2d-medium-expert-v2,model_config.task=rcbc,wandb.project=rcbc_med_exp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0565e7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/private/home/philippwu/mtm/outputs/mtm_mae/2023-01-04_17-31-35/0_+exp_mlp=d4rl_discrete,args.traj_length=2,dataset.env_name=walker2d-medium-expert-v2,model_config.task=rcbc,wandb.project=debug_rcbc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb1fa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/private/home/philippwu/mtm/outputs/mtm_mae/2023-01-04_17-51-25/2_+exp_mlp=d4rl_cont,args.traj_length=1,dataset.env_name=walker2d-medium-expert-v2,model_config.task=bc,wandb.project=debug_rcbc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad27bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find checkpoints in the directory\n",
    "steps = []\n",
    "names = []\n",
    "paths_ = os.listdir(path)\n",
    "for name in [os.path.join(path, n) for n in paths_ if \"pt\" in n]:\n",
    "    step = os.path.basename(name).split(\"_\")[-1].split(\".\")[0]\n",
    "    steps.append(int(step))\n",
    "    names.append(name)\n",
    "    #print(name)\n",
    "\n",
    "ckpt_path = names[np.argmax(steps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8556f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd54da7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt_path = '/private/home/philippwu/mtm/outputs/mtm_mae/2022-11-17_18-22-57/1_+experiments=exorl_continuous_rew_qpos,args.mask_patterns=[RANDOM,GOAL,ID,FD],args.model_config.n_dec_layer=1,args.model_config.n_enc_layer=1,args.model_config.n_head=4/model_640000.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44562698",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = Path(\"files/d4rl\")\n",
    "folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c41418b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba02fea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2a185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.load(ckpt_path)[\"step\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5253033",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = os.path.join(path, \".hydra/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9ebbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "p "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1296438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hydra_cfg = OmegaConf.load(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b496f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41892c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hydra_cfg.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7da979",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = hydra.utils.instantiate(hydra_cfg.args)\n",
    "pprint(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e6d55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = hydra.utils.call(\n",
    "    hydra_cfg.dataset,\n",
    "    # seq_steps=cfg.traj_length\n",
    "    seq_steps=1,\n",
    ")\n",
    "print(\"Train set size =\", len(train_dataset))\n",
    "print(\"Validation set size =\", len(val_dataset))\n",
    "\n",
    "tokenizers: Dict[str, Tokenizer] = {\n",
    "    k: hydra.utils.call(v, key=k, train_dataset=train_dataset)\n",
    "    for k, v in hydra_cfg.tokenizers.items()\n",
    "}\n",
    "tokenizer_manager = TokenizerManager(tokenizers)\n",
    "discrete_map: Dict[str, bool] = {}\n",
    "for k, v in tokenizers.items():\n",
    "    discrete_map[k] = v.discrete\n",
    "print(tokenizers)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    # shuffle=True,\n",
    "    pin_memory=True,\n",
    "    batch_size=cfg.batch_size,\n",
    "    num_workers=cfg.n_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    # shuffle=False,\n",
    "    batch_size=cfg.batch_size,\n",
    "    num_workers=cfg.n_workers,\n",
    ")\n",
    "train_batch = next(iter(train_loader))\n",
    "tokenized = tokenizer_manager.encode(train_batch)\n",
    "data_shapes = {}\n",
    "for k, v in tokenized.items():\n",
    "    data_shapes[k] = v.shape[-2:]\n",
    "print(data_shapes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d054635",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####################################\n",
    "################## Model\n",
    "####################################\n",
    "model_config = hydra.utils.instantiate(hydra_cfg.model_config)\n",
    "\n",
    "model = MLP_BC(data_shapes, hydra_cfg.args.traj_length, model_config)\n",
    "model.to(cfg.device)\n",
    "model.train()\n",
    "\n",
    "# load weights\n",
    "model.load_state_dict(torch.load(ckpt_path)[\"model\"])\n",
    "model.eval()\n",
    "\n",
    "####################################\n",
    "################## Model\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16073d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = val_dataset.dataset.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fddc4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "image = env.sim.render(640, 480, camera_name=\"track\")[::-1]\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeb414b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_trajectory_with_metadata = val_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e45539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_trajectory_with_metadata[\"states\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b79999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(env.sim.set_state_from_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d63f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "phys_state = np.zeros(len(sample_trajectory_with_metadata[\"states\"][0]) + 2)\n",
    "phys_state[2:] = sample_trajectory_with_metadata[\"states\"][0]\n",
    "env.sim.set_state_from_flattened(phys_state)\n",
    "env.sim.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d749468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = env.sim.render(640, 480, camera_name=\"track\")[::-1]\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846bf238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd46c8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = train_dataset.values_segmented[:, : , 0]\n",
    "returns.shape\n",
    "plt.hist(returns.flatten(), bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0638c508",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7026fa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medium dataset\n",
    "# d_dataset = hydra_cfg.dataset\n",
    "# d_dataset.env_name = \"walker2d-medium-v2\"\n",
    "# m_, _ = hydra.utils.call(\n",
    "#     d_dataset, seq_steps=cfg.traj_length\n",
    "# )\n",
    "# plt.hist(m_.values_segmented.flatten(), bins=100)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# Expert dataset\n",
    "# d_dataset = hydra_cfg.dataset\n",
    "# d_dataset.env_name = \"walker2d-expert-v2\"\n",
    "# m_, _ = hydra.utils.call(\n",
    "#     d_dataset, seq_steps=cfg.traj_length\n",
    "# )\n",
    "# plt.hist(m_.values_segmented.flatten(), bins=100)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1871cda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b51e215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_dataset = hydra_cfg.dataset\n",
    "# d_dataset.env_name = \"walker2d-random-v2\"\n",
    "# m_, _ = hydra.utils.call(\n",
    "#     d_dataset, seq_steps=cfg.traj_length\n",
    "# )\n",
    "# plt.hist(m_.values_segmented.flatten(), bins=100)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddc33e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.rewards_segmented.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624aa720",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.path_lengths[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a96971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.observation_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913925c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from research.mtm.models.mlp_model import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b7afdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cfg.learning_rate)\n",
    "print(cfg.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fb63bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    train_dataset.observation_dim,\n",
    "    train_dataset.action_dim,\n",
    "    256,\n",
    "    3\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr=cfg.learning_rate, weight_decay=cfg.weight_decay\n",
    ")\n",
    "\n",
    "\n",
    "def _schedule(step):\n",
    "    # warmp for 1000 steps\n",
    "    if step < cfg.warmup_steps:\n",
    "        return step / cfg.warmup_steps\n",
    "\n",
    "    # then cosine decay\n",
    "    assert cfg.num_train_steps > cfg.warmup_steps\n",
    "    step = step - cfg.warmup_steps\n",
    "    return 0.5 * (\n",
    "        1 + np.cos(step / (cfg.num_train_steps - cfg.warmup_steps) * np.pi)\n",
    "    )\n",
    "\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=_schedule)\n",
    "\n",
    "# optimizer = torch.optim.AdamW(\n",
    "#     model.parameters(), lr=1e-3, weight_decay=0.0001\n",
    "# )\n",
    "model.cuda()\n",
    "model.train()\n",
    "\n",
    "return_list = []\n",
    "losses = []\n",
    "step = 0\n",
    "\n",
    "use_tokenizer = True\n",
    "\n",
    "for i in range(15):\n",
    "    for batch in train_loader:\n",
    "        if use_tokenizer:\n",
    "            batch = tokenizer_manager.encode(batch)\n",
    "            actions, observations = batch[\"actions\"][:, 0, 0, :], batch[\"states\"][:, 0, 0, :]\n",
    "        else:\n",
    "            actions, observations = batch[\"actions\"][:, 0, :], batch[\"states\"][:, 0, :]\n",
    "            \n",
    "        actions = actions.to(\"cuda\")\n",
    "        observations = observations.to(\"cuda\")\n",
    "\n",
    "        pred_a = model(observations)\n",
    "        loss = torch.mean((actions - pred_a) ** 2)\n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        losses.append(loss.item())\n",
    "        step += 1\n",
    "    print(i, loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521fc576",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac75dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53201c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def sample_action_bc(\n",
    "    observation: np.ndarray,\n",
    "    traj,\n",
    "):\n",
    "    if use_tokenizer:\n",
    "        input_ = {\"states\": torch.from_numpy(observation)[None, None].to(\"cuda\")}\n",
    "        observation = tokenizer_manager.encode(input_)[\"states\"]\n",
    "        actions = model(observation)\n",
    "        decoded_logits = tokenizer_manager.decode({\"actions\": actions})\n",
    "        a = decoded_logits[\"actions\"][-1].detach().cpu().numpy()[0]\n",
    "        return a\n",
    "    else:\n",
    "        actions = model(torch.tensor(observation, device=\"cuda\")[None])\n",
    "        return actions[0].cpu().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd10b6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_d = evaluate(\n",
    "    sample_action_bc,\n",
    "    train_dataset.env,\n",
    "    20,\n",
    "    (train_dataset.observation_dim, ),\n",
    "    (train_dataset.action_dim, ),\n",
    "    num_videos=0,\n",
    ")\n",
    "e_d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64acbcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9313570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def sample_action_bc(\n",
    "    observation: np.ndarray,\n",
    "    traj,\n",
    "):\n",
    "    \"\"\"Sample action from the model.\n",
    "\n",
    "    Args:\n",
    "        observation (np.ndarray): observation\n",
    "        traj (Trajectory): traj\n",
    "    \"\"\"\n",
    "\n",
    "    input_ = {\"states\": torch.from_numpy(observation)[None, None].to(\"cuda\")}\n",
    "    logits, _ = model(\n",
    "        tokenizer_manager.encode(input_), discrete_map, compute_loss=False\n",
    "    )\n",
    "    decoded_logits = tokenizer_manager.decode({\"actions\": logits})\n",
    "    a = decoded_logits[\"actions\"][-1].detach().cpu().numpy()\n",
    "    return a[-1]\n",
    "\n",
    "\n",
    "e_d = evaluate(\n",
    "    sample_action_bc,\n",
    "    train_dataset.env,\n",
    "    10,\n",
    "    (train_dataset.observation_dim, ),\n",
    "    (train_dataset.action_dim, ),\n",
    "    num_videos=0,\n",
    ")\n",
    "e_d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daea03f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
