# @package _global_
defaults:
    - override /datasets: d4rl

tokenizers:
    states:
      _target_: research.mtm.tokenizers.uniform_bins.UniformBinningTokenizer.create
      num_bins: 512
    actions:
      _target_: research.mtm.tokenizers.uniform_bins.UniformBinningTokenizer.create
      num_bins: 512
    rewards:
      _target_: research.mtm.tokenizers.uniform_bins.UniformBinningTokenizer.create
      num_bins: 32
    returns:
      _target_: research.mtm.tokenizers.uniform_bins.UniformBinningTokenizer.create
      num_bins: 32


dataset:
    use_reward: True

args:
    _target_: research.mtm.train.RunConfig
    batch_size: 512
    n_workers: 0
    model_config:
      traj_length: 4
      norm: "none"
      n_enc_layer: 1
      n_dec_layer: 1
      n_head: 2
      n_embd: 64
    log_every: 100
    print_every: 1000
    eval_every: 10000
    save_every: 10000
    mask_patterns: ["RANDOM", "ID", "FD", "GOAL"]

wandb:
    project: "p_d4rl_disc_12_26_l2"
    resume: allow
